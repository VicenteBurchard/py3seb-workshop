{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88af1dea-5434-483b-a5ec-cac7b4998960",
   "metadata": {},
   "source": [
    "---\n",
    "title: Estimating biophysical traits using RTM inversion\n",
    "subject: Tutorial\n",
    "subtitle: Notebook to retrieve biophysical traits from satellite imagery\n",
    "short_title: Bio_RTM\n",
    "authors:\n",
    "  - name: Vicente Burchard-Levine\n",
    "    affiliation:\n",
    "      - SpecLab-CSIC\n",
    "    orcid: 0000-0003-0222-8706\n",
    "    email: vburchard@ica.csic.es\n",
    "  - name: Héctor Nieto\n",
    "    affiliations:\n",
    "      - ICA-CSIC\n",
    "    orcid: 0000-0003-4250-6424\n",
    "    email: hector.nieto@ica.csic.es\n",
    "license: CC-BY-SA-4.0\n",
    "keywords: TSEB, 3SEB, Copernicus, Satellite\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8b3328-52a6-474c-aa96-01162c09919a",
   "metadata": {},
   "source": [
    "# Summary \n",
    "\n",
    "Interactive jupyter notebook demonstrating the retrieval of biophysical variables by inverting a Radiative Transfer Model (RTM) using a hybrid appraoch, showing its applicability with Sentinel-2 imagery. \n",
    "This notebook will go through:\n",
    "\n",
    "- Builing synthetic Lool-up-Table (LUT) with pypro4sail\n",
    "- Training Random Forest algorithm with LUT\n",
    "- Evaluating Random Forest algorithm to estimate biophysical traits.\n",
    "- Inversion of Sentinel-2 bands to retrieve biophysical traits\n",
    "\n",
    "# Instructions\n",
    "Read carefully all the text and follow the instructions.\n",
    "\n",
    ":::{hint} \n",
    "\n",
    "Once each section is read, run the jupyter code cell underneath (marked as `[]`) by clicking the icon `Run`, or pressing the keys SHIFT+ENTER of your keyboard.\n",
    "\n",
    "\n",
    ":::\n",
    "\n",
    "To start, please run the following cell to import all the packages required for this notebook. Once you run the cell below, an acknowledgement message, stating all libraries were correctly imported, should be printed on screen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3117cb18-1ca2-4214-932c-60289f2642ef",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da99c248-424c-4df2-a364-eaf5b51d82e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import os \n",
    "import openeo\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import rasterio\n",
    "from osgeo import gdal\n",
    "from pathlib import Path\n",
    "import multiprocess as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pypro4sail import machine_learning_regression as inv\n",
    "from functions.biophysical import get_diffuse_radiation_6S, build_soil_database, SRF_LIBRARY, S2_BANDS\n",
    "from functions import gdal_utils as gu\n",
    "from functions.eomaji.utils import date_selector\n",
    "from sklearn.ensemble import RandomForestRegressor as rf_sklearn\n",
    "import datetime as dt\n",
    "from model_evaluation import double_collocation as dc\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import datetime\n",
    "import logging\n",
    "logging.getLogger(\"sklearnex\").setLevel(logging.ERROR)\n",
    "\n",
    "print('libraries imported correctly!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35955a9-a907-4000-9f16-0186a428c703",
   "metadata": {},
   "source": [
    "# General workflow\n",
    "\n",
    "This biophysical retrieval method essentially inverts a radiative transfer model (RTM) using a hybrid method where a machine learning (ML) algorithm between top-of-canopy reflectances and biophysical traits is trained using a physically-based RTM (i.e. PRO4SAIL) and is then applied to the Sentinel-2 bands to retrieve the different biophysical variables. This is the method used in the official Sentinel-2 biophysical processor (documentation found [**here**](https://step.esa.int/docs/extra/ATBD_S2ToolBox_V2.1.pdf)) where the workflow is shown in the figure below:\n",
    "\n",
    ":::{figure} ./input/figures/Biophysical_processor_figure.png\n",
    ":alt: S2-BIOPAR\n",
    ":name: S2-BIOPAR\n",
    "Flow chart showing how the BIOPAR products are generated operationally (figure taken from [S2 Toolbox ATDB](https://step.esa.int/docs/extra/ATBD_S2ToolBox_V2.1.pdf))\n",
    ":::\n",
    "\n",
    "\n",
    "In this notebook, we will use a very similar methodology using the pyhton implementation of [**pypro4sail**](https://github.com/hectornieto/pypro4sail). It is essentially the same method described in the above figure, but using Random Forest regressor instead of an Artificial Neural Network (ANNs) algorithm and using a more computationally efficienty Pro4SAIL model (using jacobians).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a2d2ff-8957-4fb9-a7c2-eac3f09709e6",
   "metadata": {},
   "source": [
    "# Building synthetic dataset\n",
    "\n",
    "First, we will build a synthetic dataset where a look-up-table (LUT) will be created using PRO4SAIL that relates top-of-canopy spectra and biophysical variables.\n",
    "\n",
    "The target biophysical variables are: [\"Cab\", \"Car\", \"Cm\", \"Cw\", \"Ant\", \"Cbrown\",\"LAI\", \"leaf_angle\"].\n",
    "\n",
    "### Leaf biochemical traits (from PROSPECT):\n",
    "\n",
    "- **Cab (Chlorophyll a + b content)**\n",
    "The amount of chlorophyll pigments per unit leaf area, usually expressed in µg/cm².\n",
    "\n",
    "- **Car (Carotenoid content)**\n",
    "Concentration of carotenoids (xanthophylls + carotenes) per unit leaf area, expressed in µg/cm².\n",
    "\n",
    "- **Cm (Leaf dry matter content)**\n",
    "The mass of dry matter (structural compounds like cellulose, lignin, proteins, etc.) per unit leaf area, usually in g/cm².\n",
    "\n",
    "- **Cw (Equivalent leaf water thickness)**\n",
    "The water content of the leaf per unit area, in cm (equivalent water thickness).\n",
    "\n",
    "- **Ant (Anthocyanin content)**\n",
    "Concentration of anthocyanins per unit leaf area (µg/cm²).\n",
    "\n",
    "- **Cbrown (Brown pigment content)**\n",
    "A semi-empirical parameter representing the amount of “brown pigments” (products of leaf senescence, degradation of chlorophyll, accumulation of tannins, etc.).\n",
    "\n",
    "### Canopy structural traits (from SAIL):\n",
    "\n",
    "- **LAI (Leaf Area Index)**\n",
    "Total one-sided leaf area per unit ground area (m²/m²).\n",
    "\n",
    "- **leaf_angle (Leaf angle distribution parameter)**\n",
    "A parameter describing the average orientation of leaves in the canopy, often represented by an ellipsoidal distribution.\n",
    "Low values → leaves more horizontally oriented (planophile).\n",
    "High values → leaves more vertically oriented (erectophile).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3c017b-8294-4d1d-8773-56406dde29cd",
   "metadata": {},
   "source": [
    "## Forward RTM simulations to build LUT\n",
    "\n",
    "We will perform 40000 PRO4SAIL simulations in Forward mode (i.e. using vegetation paramters to simulate surface reflectance based on the RTM's description of light-canopy intereactions) using global vegetation parameters bounds as specified below, which are taken from global datasets (e.g. [**LOPEX**](https://ecosis.org/package/leaf-optical-properties-experiment-database--lopex93-)). This is done to be able to train the model over a wide range of condtions and be globally applicable.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f735e37-4a9c-4878-b2c7-04a88c3df235",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_simulations = 40000\n",
    "\n",
    "# parameter names\n",
    "OBJ_PARAM_NAMES = [\"Cab\", \"Car\", \"Cm\", \"Cw\", \"Ant\", \"Cbrown\",\n",
    "                   \"LAI\", \"leaf_angle\"]\n",
    "# parameter info\n",
    "PARAM_PROPS = {\"Cab\": [\"Chlorophyll a+b\", r\"$\\mu g\\,cm^{-2}$\", 1],\n",
    "               \"Car\": [\"Carotenoids\", r\"$\\mu g\\,cm^{-2}$\", 1],\n",
    "               \"Cm\": [\"Dry matter\", r\"$g\\,cm^{-2}$\", 3],\n",
    "               \"Cw\": [\"Water content\", r\"$g\\,cm^{-2}$\", 3],\n",
    "               \"Ant\": [\"Antocyanins\", r\"$\\mu g\\,cm^{-2}$\", 1],\n",
    "               \"Cbrown\": [\"Brown pigments\", r\"$-$\", 1],\n",
    "               \"LAI\": [\"Leaf Area Index\", r\"$m^{2}\\,m^{-2}$\", 2],\n",
    "               \"leaf_angle\": [\"Mean leaf inclination angle\", r\"º\", 1]}\n",
    "\n",
    "# specify range of variable values\n",
    "## minimum\n",
    "MIN_N_LEAF = 1.0  # From LOPEX + ANGERS average\n",
    "MIN_CAB = 0.0  # From LOPEX + ANGERS average\n",
    "MIN_CAR = 0.0  # From LOPEX + ANGERS average\n",
    "MIN_CBROWN = 0.0  # from S2 L2B ATBD\n",
    "MIN_CM = 0.0017  # From LOPEX + ANGERS average\n",
    "MIN_CW = 0.000  # From LOPEX + ANGERS average\n",
    "MIN_ANT = 0.0\n",
    "MIN_LAI = 0.0\n",
    "MIN_LEAF_ANGLE = 30.0  # from S2 L2B ATBD\n",
    "MIN_HOTSPOT = 0.1  # from S2 L2B ATBD\n",
    "MIN_BS = 0.50  # from S2 L2B ATBD\n",
    "\n",
    "## maximum\n",
    "MAX_N_LEAF = 3.0  # From LOPEX + ANGERS average\n",
    "MAX_CAB = 110.0  # From LOPEX + ANGERS average\n",
    "MAX_CAR = 30.0  # From LOPEX + ANGERS average\n",
    "MAX_CBROWN = 2.00  # from S2 L2B ATBD\n",
    "MAX_CM = 0.0331  # From LOPEX + ANGERS average\n",
    "MAX_CW = 0.0525  # From LOPEX + ANGERS average\n",
    "MAX_ANT = 40.0\n",
    "MAX_LAI = 5  # from S2 L2B ATBD\n",
    "MAX_LEAF_ANGLE = 80.0  # from S2 L2B ATBD\n",
    "MAX_HOTSPOT = 0.5  # from S2 L2B ATBD\n",
    "MAX_BS = 3.5  # from S2 L2B ATBD\n",
    "\n",
    "prosail_bounds = {'N_leaf': (MIN_N_LEAF, MAX_N_LEAF),\n",
    "                  'Cab': (MIN_CAB, MAX_CAB),\n",
    "                  'Car': (MIN_CAR, MAX_CAR),\n",
    "                  'Cbrown': (MIN_CBROWN, MAX_CBROWN),\n",
    "                  'Cw': (MIN_CW, MAX_CW),\n",
    "                  'Cm': (MIN_CM, MAX_CM),\n",
    "                  'Ant': (MIN_ANT, MAX_ANT),\n",
    "                  'LAI': (MIN_LAI, MAX_LAI),\n",
    "                  'leaf_angle': (MIN_LEAF_ANGLE, MAX_LEAF_ANGLE),\n",
    "                  'hotspot': (MIN_HOTSPOT, MAX_HOTSPOT),\n",
    "                  'bs': (MIN_BS, MAX_BS)}\n",
    "df_bounds = pd.DataFrame(prosail_bounds, index=['min', 'max'])\n",
    "n_simulations = 40000\n",
    "print(f'Setting up {n_simulations} simulations with inputs bounds:\\n\\n {df_bounds[OBJ_PARAM_NAMES]}')\n",
    "params_orig = inv.build_prosail_database(n_simulations,\n",
    "                                         param_bounds=prosail_bounds,\n",
    "                                         distribution=inv.SALTELLI_DIST)\n",
    "print('\\nDone!')\n",
    "print('Table with simulation inputs:')\n",
    "pd.DataFrame(params_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b61496-655e-428c-a0ae-54ffe164f03c",
   "metadata": {},
   "source": [
    "## Estimate diffuse irradiance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e901bd0-9363-4841-8cb3-b8e24f8b9706",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Running 6S for estimation of diffuse/direct irradiance\")\n",
    "# specify geometric variables (this normally can be acquired from Sentinel-2 metadata)\n",
    "# As an example, we specify default values\n",
    "aot = 1. # Aerosol optical thicness\n",
    "wvp = 25. # water vapour\n",
    "sza = 37.5 # sun zenith angle\n",
    "saa = 180 # sun azimuth angle\n",
    "vza = 25 # sensor viewing angle\n",
    "\n",
    "# specify date\n",
    "date_obj = dt.datetime(2023, 8, 5, 10, 30)\n",
    "\n",
    "skyl = get_diffuse_radiation_6S(aot, wvp, sza, saa, date_obj,\n",
    "                                                   altitude=0.1)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5502d2d8-93b3-46cf-9072-7c2a3b5a5ad7",
   "metadata": {},
   "source": [
    "## Build soil spectral database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01ece81-75a9-4e9d-8077-978275cda687",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Building {np.size(params_orig['bs'])} PROSPECTD+4SAIL simulations\")\n",
    "soil_spectrum = build_soil_database(params_orig[\"bs\"])\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db88c4d2-20ad-4bfc-811a-412c6ceee264",
   "metadata": {},
   "source": [
    "# Simulate Sentinel-2 spectra\n",
    "\n",
    "We are interested in inverting Sentinel-2 top-of-canopy reflectance to retrieve the biophysical variables. As such, we will need to take into account the chracteristics of the Sentinel-2 sensor.\n",
    "\n",
    "\n",
    ":::{figure} ./input/figures/S2_bands_info.jpg\n",
    ":alt: S2\n",
    ":name: S2-bands\n",
    "Sentinel-2 MSI bands information (figure taken from [Pasqualotto et al. 2019](https://ieeexplore.ieee.org/document/8909218))\n",
    ":::\n",
    "\n",
    "In this case, we will use bands ['B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B11', 'B12'] as our 'features' to invert the RTM.\n",
    "\n",
    "First, will need to convolve the surface reflectance to the spectral response function (SRF) of the Sentinel-2 sensor to best simulate this sensor.\n",
    "\n",
    "### Visualize Sentinel-2 Spectral Response Function (SRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdcc8fb-2cf8-423d-9d35-08439693763d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bands to use in generating LUT and inversion\n",
    "S2_BANDS = ['B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B11', 'B12']\n",
    "# Stack spectral bands\n",
    "srf = []\n",
    "srf_file = SRF_LIBRARY / f'Sentinel2A.txt'\n",
    "srfs = np.genfromtxt(srf_file, dtype=None, names=True)\n",
    "for band in S2_BANDS:\n",
    "    srf.append(srfs[band])\n",
    "\n",
    "\n",
    "# open as pandas dataframe\n",
    "srf_df = pd.read_csv(srf_file, sep = '\\t')\n",
    "\n",
    "band_names = srf_df[S2_BANDS].columns\n",
    "\n",
    "# plot spectral response function\n",
    "colormap = plt.cm.rainbow # Choose a colormap\n",
    "# get color within colormap range for each band (depends on number of bands)\n",
    "colors = [colormap(x / (len(band_names) - 1)) for x in range(len(band_names))]\n",
    "\n",
    "# Show spectral response function (SRF) curves\n",
    "plt.figure(figsize=(9, 5))\n",
    "plt.title(f'Spectral Response Function (SRF) - Sentinel-2', fontsize=14)\n",
    "plt.xlabel('Wavelength (nm)', fontsize=12)\n",
    "plt.xlim(400, 2500)\n",
    "plt.ylabel('Relative Response (-)', fontsize=12)\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(True)\n",
    "i = 0\n",
    "for band in band_names:\n",
    "    plt.plot(srf_df['SR_WL'], srf_df[band], color=colors[i], label = f'{str(band)}')\n",
    "    i += 1\n",
    "\n",
    "plt.legend(loc='lower right', ncol=5)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63037054-b8a9-43fe-a439-48fb1cc0a042",
   "metadata": {},
   "source": [
    "## Build simulated Sentinel-2-like Look-Up-Table (LUT)\n",
    "\n",
    "Here we will mimic sentinel-2 surface reflectance using the PRO4SAIL RTM. For this testing, we will assume certain geometric and atmospheric conditions with specific values for sun zenith angle (sza), sun azimuth angle (saa), sensor viewing zenith angle (vza), water vapour (wvp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05527799-6e60-4db8-81e6-63f0130e5986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to save the LUT generating you can can specify a directory for lut_outfile\n",
    "lut_outfile = None\n",
    "\n",
    "# spectral range\n",
    "wls_sim = np.arange(400, 2501)\n",
    "\n",
    "# number of CPUs to use to perform simulations \n",
    "# (can change depending on number of CPUs in your computer)\n",
    "njobs = 4\n",
    "\n",
    "# generate LUT\n",
    "rho_canopy_vec, params = inv.simulate_prosail_lut_parallel(\n",
    "        njobs,\n",
    "        params_orig,\n",
    "        wls_sim,\n",
    "        soil_spectrum,\n",
    "        skyl=skyl,\n",
    "        sza=sza,\n",
    "        vza=vza,\n",
    "        psi=0,\n",
    "        srf=srf,\n",
    "        outfile=lut_outfile,\n",
    "        calc_FAPAR=False,\n",
    "        reduce_4sail=True)\n",
    "\n",
    "print('Done!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f5a0db-7fef-4490-b874-4257648e2e53",
   "metadata": {},
   "source": [
    "# Training model using synthetic LUT\n",
    "\n",
    "Here we will train a Random Forest (RF) regressor with [**Scikit-learn**](https://scikit-learn.org/stable/) from the synthetic LUT generated with the PROSAIL simulations, which relate Sentinel-2 bands with biophysical variables.\n",
    "\n",
    "We train individual RF models for each target variables (i.e. LAI, Cab, Car, Cm, Cw, Ant, Cbrown, leaf_angle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00251882-b81a-4a98-8fe2-72c91ffbe149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach 1: Train individual random forest model for each variable\n",
    "print(f\"Training {len(OBJ_PARAM_NAMES)} Random forests for \"\n",
    "      f\"{','.join(OBJ_PARAM_NAMES)}\")\n",
    "\n",
    "# RF paramters\n",
    "scikit_regressor_opts = {\"n_estimators\": 100,\n",
    "                         \"min_samples_leaf\": 1,\n",
    "                         \"n_jobs\": -1}\n",
    "\n",
    "start_time = dt.datetime.today()\n",
    "input_scalers = {}\n",
    "output_scalers = {}\n",
    "regs = {}\n",
    "for i, param in enumerate(OBJ_PARAM_NAMES):\n",
    "    reg, input_gauss_scaler, output_gauss_scaler, _ = \\\n",
    "        inv.train_reg(rho_canopy_vec,\n",
    "                      params[param].reshape(-1, 1),\n",
    "                      scaling_input='normalize',\n",
    "                      scaling_output='normalize',\n",
    "                      regressor_opts=scikit_regressor_opts,\n",
    "                      reg_method=\"random_forest\")\n",
    "\n",
    "    input_scalers[param] = input_gauss_scaler\n",
    "    output_scalers[param] = output_gauss_scaler\n",
    "    regs[param] = reg\n",
    "    \n",
    "end_time_standard = dt.datetime.today() - start_time\n",
    "\n",
    "print(\"\\nProcessing time (Training):\")\n",
    "print(f\"\\t{len(OBJ_PARAM_NAMES)} Random forests: {end_time_standard}\")\n",
    "    \n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3a4fcb-71f0-488d-9bcf-fe7883f97647",
   "metadata": {},
   "source": [
    "# Testing model\n",
    "\n",
    "We will now test the RF regression model using synthetic sentinel-2-like reflectance to see how well the trained RF model can simulate the RTM. In this case, we will add some random noise to the testing surface reflectance to better mimic real conditions that occur with optical sensors. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65cdeed-8282-4d58-8994-9be688ac86bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create synthetic Sentine-2-like spectra\n",
    "rho_canopy_test, params_test = inv.simulate_prosail_lut_parallel(\n",
    "        njobs,\n",
    "        params_orig,\n",
    "        wls_sim,\n",
    "        soil_spectrum,\n",
    "        skyl=skyl,\n",
    "        sza=sza,\n",
    "        vza=vza,\n",
    "        psi=0,\n",
    "        srf=srf,\n",
    "        outfile=None,\n",
    "        calc_FAPAR=False,\n",
    "        reduce_4sail=True)\n",
    "\n",
    "# set how much noise to add (either relative or absolute)\n",
    "rel_unc = 0.1\n",
    "abs_unc = 0.015\n",
    "RELATIVE_UNC = 1\n",
    "ABSOLUTE_UNC = 0\n",
    "noise_method = RELATIVE_UNC\n",
    "# add noise to mimic real conditions\n",
    "if noise_method == RELATIVE_UNC:\n",
    "    stdev = rho_canopy_test * rel_unc\n",
    "    white_noise = np.random.normal(scale=stdev, size=rho_canopy_test.shape)\n",
    "    rho_canopy_test = rho_canopy_test * (1 + white_noise)\n",
    "else:\n",
    "    white_noise = np.random.normal(scale=abs_unc, size=rho_canopy_test.shape)\n",
    "    rho_canopy_test = rho_canopy_test + white_noise\n",
    "    \n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26739835-0089-4b20-9d1a-b684e4d12e04",
   "metadata": {},
   "source": [
    "# Evaluation of the retrievals of biophysical variables\n",
    "\n",
    "Now we will apply the trained model on the testing dataset to see how well we can estimate the biophysical traits using this hybrid approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b115747-bc45-487a-a124-9ff120fc5bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = 16 / 2.45, 22 / 2.45\n",
    "\n",
    "start_time = dt.datetime.today()\n",
    "# Apply individual RF model to test data\n",
    "print(f\"Applying individual RF regression model to Sentinel-like spectra\")\n",
    "output_regs = {}\n",
    "for i, param in enumerate(OBJ_PARAM_NAMES):\n",
    "    output = output_scalers[param].inverse_transform(\n",
    "        regs[param].predict(\n",
    "            input_scalers[param].transform(\n",
    "                rho_canopy_test)).reshape(-1, 1)).reshape(-1)\n",
    "    output_regs[param] = output\n",
    "\n",
    "end_time_standard = dt.datetime.today() - start_time\n",
    "\n",
    "print(\"\\nProcessing time (Testing):\")\n",
    "print(f\"\\t{len(OBJ_PARAM_NAMES)} Random forests: {end_time_standard}\")\n",
    "print('\\nPloting scatter plots...')\n",
    "#outfile = out_dir / f\"evaluation_singleRF.eps\"\n",
    "fig, axs = plt.subplots(ncols=2, nrows=4,\n",
    "                        figsize=figsize)\n",
    "\n",
    "fig.supxlabel(\"Estimated\")\n",
    "fig.supylabel(\"Observed\")\n",
    "\n",
    "axs = axs.reshape(-1)\n",
    "error_table = pd.DataFrame({\"Trait\" : [], \"N\": [], \"bias\": [],\n",
    "                            \"RMSE\": [], \"r\": []})\n",
    "for i, param in enumerate(OBJ_PARAM_NAMES):\n",
    "    name, unit, decs = PARAM_PROPS[param]\n",
    "    txt_template =  (\"   N: {:>6d}\\n\"\n",
    "                     \"bias: {:>6.%sf}\\n\"\n",
    "                     \"RMSE: {:>6.%sf}\\n\"\n",
    "                     \"   r: {:>6.2f}\")%(decs, decs)\n",
    "    \n",
    "    test = output_regs[param]\n",
    "    cor, *_ = dc.agreement_metrics(params_test[param] ,test)\n",
    "    bias, mae, rmse = dc.error_metrics(params_test[param], test)\n",
    "    dc.density_plot(test, params_test[param], axs[i], s=1, rasterized=True)\n",
    "\n",
    "    absline = np.asarray([[np.amin(params_test[param]), np.amax(params_test[param])],\n",
    "                          [np.amin(params_test[param]), np.amax(params_test[param])]])\n",
    "\n",
    "    axs[i].plot(absline[0], absline[1], \"k:\")\n",
    "    axs[i].set_title(f\"{name} ({unit})\")\n",
    "    axs[i].text(0.05,\n",
    "                0.95,\n",
    "                txt_template.format(len(test), bias, rmse, cor),\n",
    "                va=\"top\",\n",
    "                fontfamily=\"monospace\",\n",
    "                transform=axs[i].transAxes)\n",
    "\n",
    "    error_dict = {\"Trait\" : [param], \"N\": [len(test)], \"bias\": [bias],\n",
    "                  \"RMSE\": [rmse], \"r\": [cor]}\n",
    "    error_table = pd.concat([error_table, pd.DataFrame(error_dict)],\n",
    "                            ignore_index=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print('Error metrics table:')\n",
    "error_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ae5e7e-b4ee-4513-bf06-1f87e73da510",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "As shown, this hybrid approach allows to train an empirical RF regressor based on the simulations of synthetic datasets of surface reflectance and biophysical variables from a physically-based RTM. This trained model can then be easily applied to Sentinel-2 imagery and is much more computationally efficient than inverting an RTM using traditional approaches.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f347829-432e-4afc-8575-3312a551f79c",
   "metadata": {},
   "source": [
    "# Apply RF model to real Sentinel-2 image\n",
    "\n",
    "Let us now apply this trained model on sentinel-2 image to retrieve the different biophysical traits. \n",
    "\n",
    "We wil again acquire the data from the Copernicus Data Space Ecosystem (CDSE).\n",
    "\n",
    ":::{important}\n",
    "\n",
    "In order to execute this notebook, you will need to register in the [**Copernicus Data Space Ecosystem (CSDE)**](https://dataspace.copernicus.eu/) to acquire and process Sentinel-2 imagery.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98822f4-27a8-4036-8192-52cb8e4fa41e",
   "metadata": {},
   "source": [
    "## Connect to OpenEO Backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813b73c1-570b-4a00-abdd-83b840a75455",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = openeo.connect(\"https://openeo.dataspace.copernicus.eu\")\n",
    "connection.authenticate_oidc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53a37e6-9e0e-4b26-9264-572e2d130a91",
   "metadata": {},
   "source": [
    "### Visualize information of Sentinel-2 collection\n",
    "\n",
    "We can get all the band and metadta information related to the Sentinel-2 L2A product with the *connection.describe_collection(\"SENTINEL2_L2A\")* function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c879c72d-ca5a-408b-99a3-1f36238d995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.describe_collection(\"SENTINEL2_L2A\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643d88e0-1b27-4c97-86ac-178ca357df95",
   "metadata": {},
   "source": [
    "# Load Sentinel-2 image using OpenEO\n",
    "\n",
    "Choose date and area of interest of sentinel-2 imager\n",
    "\n",
    ":::{note}\n",
    "\n",
    "By default, we will use the image acquired over the WES Almond orchard near the UAV overpass (April 16th 2024)\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803b4206-a99f-45c5-8fc7-5eb6334baa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define search parameters\n",
    "date = datetime.date(2024, 4, 16)\n",
    "bbox = [-121.35,37.45, -121.10, 37.65] # please insert a bbox here in the form of [minx, miny, maxx, maxy\n",
    "time_window = [\n",
    "        str(date + relativedelta(days=-3)),\n",
    "        str(date + relativedelta(days=+3)),\n",
    "    ]\n",
    "aoi = dict(zip([\"west\", \"south\", \"east\", \"north\"], bbox))\n",
    "\n",
    "s2_ref_bands = [\n",
    "        \"B02\",\n",
    "        \"B03\",\n",
    "        \"B04\",\n",
    "        \"B05\",\n",
    "        \"B06\",\n",
    "        \"B07\",\n",
    "        \"B08\",\n",
    "        \"B8A\",\n",
    "        \"B11\",\n",
    "        \"B12\"\n",
    "    ]\n",
    "\n",
    "s2_meta_bands = [\"SCL\",\n",
    "                 'WVP',\n",
    "                 'AOT',\n",
    "                 'sunAzimuthAngles',\n",
    "                 'sunZenithAngles',\n",
    "                 'viewZenithMean'\n",
    "                ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b89361-147f-4a83-af20-37f47d5bdf39",
   "metadata": {},
   "source": [
    "### Pre-process Sentinel-2 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee388f5f-925f-4832-898f-3e74feff82ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up outfile\n",
    "s2_dir =  Path(\"./dataset/sentinel_imagery\")\n",
    "s2_outfile = s2_dir / \"s2_cube_bio.nc\"\n",
    "\n",
    "overwrite = False\n",
    "\n",
    "if s2_outfile.exists() and overwrite == False:\n",
    "    print(f'{s2_outfile} already exists..')\n",
    "else:\n",
    "    print('Loading S2 data cube from Copernicus Data Space Ecosystem..')\n",
    "    # Load Sentinel-2 cube and merge with Biopar\n",
    "    s2_cube = connection.load_collection(\n",
    "        \"SENTINEL2_L2A\", spatial_extent=aoi, temporal_extent=time_window, bands=s2_ref_bands+s2_meta_bands)\n",
    "    \n",
    "    print('Mask out non-vegetated pixels...')\n",
    "    # Apply cloud and shadow mask using SCL (keep only class 4 and 5 = vegetation/bare)\n",
    "    mask = ~((s2_cube.band(\"SCL\") == 4) | (s2_cube.band(\"SCL\") == 5))\n",
    "    s2_masked = s2_cube.mask(mask)\n",
    "    \n",
    "    print('Select best available pixel from time window')\n",
    "    # Reduce time dimension by selecting the first valid observation\n",
    "    s2_best_pixel = s2_masked.reduce_dimension(dimension=\"t\", reducer=\"first\")\n",
    "    \n",
    "    print(f'Saving s2 cube as {s2_outfile} .. ')\n",
    "    s2_best_pixel.download(str(s2_outfile))\n",
    "    \n",
    "    print(f'Loading {str(s2_outfile)} as xarray object')\n",
    "    \n",
    "s2_cube =  xr.open_dataset(str(s2_outfile))\n",
    "\n",
    "# get geographic metadata \n",
    "x_utm = s2_cube['B02']['x']\n",
    "y_utm = s2_cube['B02']['y']\n",
    "# Pixel size\n",
    "dx = float((x_utm[1] -x_utm[0]))\n",
    "dy = float((y_utm[1] - y_utm[0]))\n",
    "\n",
    "# Top-left corner \n",
    "x_min = float(s2_cube['x'].min())\n",
    "y_max = float(s2_cube['y'].max())\n",
    "#geotransform\n",
    "gt = (x_min, dx, 0.0, y_max, 0.0, dy)\n",
    "# projection\n",
    "prj =  s2_cube.crs.spatial_ref\n",
    "\n",
    "\n",
    "print(f'Extracting {S2_BANDS} as 3D array cube')\n",
    "# These are the Sentinel 2 bands to use RTM inversion\n",
    "s2_xarray = s2_cube[S2_BANDS].to_array(dim=\"band\").rio.write_crs(rasterio.crs.CRS.from_string(prj).to_string())\n",
    "s2_ar = s2_xarray.values/10000\n",
    "# get metadata and store in dictionary\n",
    "meta_dict = {}\n",
    "for var in s2_meta_bands:\n",
    "    print(f'Extracting {var} as array')\n",
    "    var_ar = s2_cube[[var]].to_array(dim=\"band\").values[0]\n",
    "    meta_dict[var] = var_ar\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc53704-a5c9-4b52-bf38-f2dc6f0617ea",
   "metadata": {},
   "source": [
    "# Build database based on geometric conditions\n",
    "Now, we will train the model based the actual geometric and atmospheric conditions during the Sentinel-2 overpass. For this, we will again build the LUT using PROSAIL and the metadata provided in the Sentinel-2 images.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c41fdfd-c2b7-4f63-8919-71bbe6fb226d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sun/viewing angles\n",
    "sza = np.nanmean(meta_dict['sunZenithAngles'])\n",
    "saa = np.nanmean(meta_dict['sunAzimuthAngles'])\n",
    "vza = np.nanmean(meta_dict['viewZenithMean'])\n",
    "# get aerosol optical thickness and water vapour\n",
    "aot = np.nanmean(meta_dict['AOT'])/1000\n",
    "wvp = np.nanmean(meta_dict['WVP'])/1000\n",
    "\n",
    "date_obj = dt.datetime(2024, 4, 16, 10, 30)\n",
    "\n",
    "print(\"Running 6S for estimation of diffuse/direct irradiance\")\n",
    "skyl = get_diffuse_radiation_6S(aot, wvp, sza, saa, date_obj,\n",
    "                                altitude=0.1)\n",
    "\n",
    "print(f\"Building {np.size(params_orig['bs'])} PROSPECTD+4SAIL simulations\")\n",
    "soil_spectrum = build_soil_database(params_orig[\"bs\"])\n",
    "\n",
    "# spectral range\n",
    "wls_sim = np.arange(400, 2501)\n",
    "\n",
    "# number of CPUs to use to perform simulations\n",
    "njobs = 4\n",
    "# generate LUT\n",
    "rho_canopy_vec, params = inv.simulate_prosail_lut_parallel(\n",
    "        njobs,\n",
    "        params_orig,\n",
    "        wls_sim,\n",
    "        soil_spectrum,\n",
    "        skyl=skyl,\n",
    "        sza=sza,\n",
    "        vza=vza,\n",
    "        psi=0,\n",
    "        srf=srf,\n",
    "        outfile=lut_outfile,\n",
    "        calc_FAPAR=False,\n",
    "        reduce_4sail=True)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700fa1b4-1266-43b0-8423-5b2c38ebd8de",
   "metadata": {},
   "source": [
    "# Train RF model\n",
    "As before, we will now train the RF algorithm based on the simulated LUT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6403f52c-d610-46c9-a52d-00324f506fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training Random forest for {','.join(OBJ_PARAM_NAMES)}\")\n",
    "input_scalers = {}\n",
    "output_scalers = {}\n",
    "regs = {}\n",
    "for i, param in enumerate(OBJ_PARAM_NAMES):\n",
    "    reg, input_gauss_scaler, output_gauss_scaler, _ = \\\n",
    "        inv.train_reg(rho_canopy_vec, params[param].reshape(-1, 1),\n",
    "                      scaling_input=\"normalize\", scaling_output=\"normalize\",\n",
    "                      regressor_opts=scikit_regressor_opts,\n",
    "                      reg_method=\"random_forest\")\n",
    "\n",
    "    input_scalers[param] = input_gauss_scaler\n",
    "    output_scalers[param] = output_gauss_scaler\n",
    "    regs[param] = reg\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb409a4-f919-4425-944d-134973c27ed5",
   "metadata": {},
   "source": [
    "# Apply model on S2 \n",
    "\n",
    "Now, let us apply the trained RF model on the Sentinel-2 imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf51cfd1-7543-4d7b-aa1d-91192951a543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 2D dimensions of array\n",
    "dims = s2_ar[0,:,:].shape\n",
    "\n",
    "# only select vegetation/soil pixels\n",
    "valid = np.logical_or(meta_dict['SCL'] == 4, meta_dict['SCL'] == 5)\n",
    "valid = np.ravel(valid)\n",
    "image_array = s2_ar.reshape((s2_ar.shape[0], -1)).T\n",
    "image_array = image_array[valid]\n",
    "bio_dict = {}\n",
    "for i, param in enumerate(OBJ_PARAM_NAMES):\n",
    "    output = np.full(valid.size, np.nan)\n",
    "    print(f\"Appliying {param} model to S2 image reflectance array\")\n",
    "    if np.any(valid):\n",
    "        output[valid] = output_scalers[param].inverse_transform(\n",
    "            regs[param].predict(input_scalers[param].transform(\n",
    "                image_array)).reshape(-1, 1)).reshape(-1)\n",
    "    \n",
    "    output = output.reshape(dims)\n",
    "    \n",
    "    if param == 'fAPAR' or param == 'fIPAR':\n",
    "        min_value = 0\n",
    "        max_value = 1\n",
    "    else:\n",
    "        min_value = inv.prosail_bounds[param][0]\n",
    "        max_value = inv.prosail_bounds[param][1]\n",
    "    \n",
    "    output = np.clip(output, min_value, max_value)\n",
    "    # save to dictionary\n",
    "    bio_dict[param] = output\n",
    "    output_name = f\"S2_{param}_{date.strftime('%Y%m%d')}.tif\"\n",
    "    output_file = s2_dir / output_name\n",
    "    print(f\"Saving {param} in {output_file}\\n\")\n",
    "    gu.save_image(output, gt, prj, output_file)\n",
    "    \n",
    "    del output\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f33cb24-6bf8-4788-a992-4a5bdf5fb4c0",
   "metadata": {},
   "source": [
    "# Visualize retrieved biophysical outputs \n",
    ":::{note}\n",
    "You can also visualize the retrieved biophysical products in QGIS. The rasters should be saved in *\"./dataset/sentinel_imagery\"*\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18c1611-7b71-492c-9ce7-64ca9ddeb10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get extent [minx, maxx, miny, maxy] of scene\n",
    "te = [float(s2_cube['x'].min()), float(s2_cube['x'].max()), float(s2_cube['y'].min()), float(s2_cube['y'].max())]\n",
    "\n",
    "# visualizing outputs \n",
    "variables = ['LAI', 'Cab', 'Cw']\n",
    "\n",
    "fig, axes = plt.subplots(1,3, figsize=(12, 6))\n",
    "for i,var in enumerate(variables):\n",
    "    name, unit, _ = PARAM_PROPS[var]\n",
    "    range_lim = prosail_bounds[var]\n",
    "    \n",
    "    if var == 'LAI':\n",
    "        cmap = 'YlGn'\n",
    "    elif var == 'Cab':\n",
    "        cmap = 'PiYG'\n",
    "    else:\n",
    "        cmap = 'BrBG'\n",
    "    \n",
    "    # entire ROI\n",
    "    ax = axes[i]\n",
    "    ar = bio_dict[var]\n",
    "    \n",
    "    im = ax.imshow(ar, vmin=range_lim[0], vmax=range_lim[1], cmap=cmap, extent = te)\n",
    "    ax.set_title(f'{name}', fontsize=14)\n",
    "    # Add colorbar \n",
    "    cbar = fig.colorbar(im, ax=ax, shrink=0.95, orientation='horizontal')\n",
    "    cbar.set_label(f'{var} ({unit})', fontsize=12)  # Add title to colorbar\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505580f6-dffe-404c-bfd4-57c356aaa827",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "- Hybrid RTM approach is an effective method combining physically-based modeling with machine learning algotithms\n",
    "- Since the calibration is performed with synthetic dataset, no in-situ data is required making it globally applicable\n",
    "\n",
    ":::{warning}\n",
    "\n",
    "The effectiveness of these methods also depend on the assumptions made in the PRO4SAIL model, which assumes a horizontally and vertically homogeneous turbid vegetation layer. These methods tend to work relatively well in structurally homogenous vegetation such as herbaceous crops/vegetation but uncertainties may be greater in complex agro-forestry systems which have more heterogeneous characteristics (e.g. clumping, multiple vegetation layers, senecent vegetation). \n",
    ":::\n",
    "\n",
    ":::{note}\n",
    "Please feel free comment any thoughts. This is work in progress!!!\n",
    ":::"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
