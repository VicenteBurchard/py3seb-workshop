from pathlib import Path
import multiprocessing as mp
import numpy as np
import pandas as pd
import datetime as dt
from osgeo import gdal
import Py6S as sixs
from pypro4sail import machine_learning_regression as inv
from pyTSEB import meteo_utils as met
from functions import gdal_utils as gu
from functions import cloud_mask as cm
from functions import helpers as hp
from meteo_utils import ecmwf_utils as eu
from oslo_concurrency import lockutils
import logging

lockutils.set_defaults(lock_path=Path.home() / "temp")
log = logging.getLogger(__name__)
AOT_SCALE = 1e3
BOA_SCALE = 1e4
VZN_SCALE = 1e2
WVP_SCALE = 1e3

S2_BANDS = ["B02", "B03", "B04", "B05", "B06",
            "B07", "B08", "B8A", "B11", "B12"]

S3_BANDS = ['O2', 'O3', 'O4', 'O5', 'O6', 
            'O7', 'O8', 'O9', 'O10', 'O11',
            'O12', 'O16', 'O17', 'O18', 'O21',
            'S5', 'S6']

LND_BANDS = ["B2", "B3", "B4", "B5", "B6", "B7"]
OBJ_PARAM_NAMES = ["Cab", "Car", "Cm", "Cw", "Ant", "Cbrown",
                   "LAI", "leaf_angle"]

LOCAL_OVERPASS_TIME = 10.5

DEFAULT_AOD = 0.1
DEFAULT_WVP = 1.0

# Path to the pyPro4SAIL soil library and SRF library
SOIL_LIBRARY = Path(inv.__file__).parent / "spectra" / "soil_spectral_library"
SRF_LIBRARY = Path(inv.__file__).parent / "spectra" / "sensor_response_functions"
ALBEDO_LIBRARY = Path(__file__).absolute().parent / "narrow2broadband"


def get_diffuse_radiation_6S(aot, wvp, sza, saa, date,
                             altitude=0.1, wls_step=10, n_jobs=None):

    s = sixs.SixS()
    s.atmos_profile = sixs.AtmosProfile.PredefinedType(
                            sixs.AtmosProfile.MidlatitudeSummer)

    s.aeroprofile = sixs.AeroProfile.PredefinedType(
                            sixs.AeroProfile.Continental)
    
    s.ground_reflectance = sixs.GroundReflectance.HomogeneousLambertian(0)

    if np.isfinite(wvp) and wvp > 0:
        s.atmos_profile = sixs.AtmosProfile.UserWaterAndOzone(wvp, 0.9)
    
    if np.isfinite(aot) and aot > 0:
        s.aot550 = aot

    s.geometry.solar_z = sza
    s.geometry.solar_a = saa
    s.geometry.view_z = 0
    s.geometry.view_a = 0
    s.geometry.day = date.day
    s.geometry.month = date.month

    s.altitudes.set_target_custom_altitude(altitude)
    s.wavelength = sixs.Wavelength(0.4, 2.5)

    wls = np.arange(400, 2501)
    wls_sim = np.arange(400, 2501, wls_step)

    wv, res = sixs.SixSHelpers.Wavelengths.run_wavelengths(s,
                                                           wls_sim / 1000.,
                                                           verbose=False,
                                                           n=n_jobs)
    
    eg_d = np.array(sixs.SixSHelpers.Wavelengths.extract_output(res, 
                                                    'diffuse_solar_irradiance'))
    
    eg_s = np.array(sixs.SixSHelpers.Wavelengths.extract_output(res, 
                                                    'direct_solar_irradiance'))
    
    eg_d = np.maximum(eg_d, 0)
    eg_s = np.maximum(eg_s, 0)
    skyl = np.full_like(wls, np.nan, dtype=np.float64)
    # Fill the diffuse values into a full wavelenght array
    valid = np.in1d(wls, wls_sim, assume_unique=True)
    skyl[valid] = eg_d / (eg_d + eg_s)
    # Fill nans by linear interpolation
    nans, x = np.isnan(skyl), lambda z: z.nonzero()[0]
    skyl[nans] = np.interp(x(nans), x(~nans), skyl[~nans])    
    
    return skyl


def build_soil_database(soil_albedo_factor,
                        soil_library=SOIL_LIBRARY):

    soil_library = Path(soil_library)
    n_simulations = np.size(soil_albedo_factor)
    soil_files = list(soil_library.glob('jhu.*spectrum.txt'))
    n_soils = len(soil_files)
    soil_spectrum = []
    for soil_file in soil_files:
        r = np.genfromtxt(soil_file)
        soil_spectrum.append(r[:, 1])

    multiplier = int(np.ceil(float(n_simulations / n_soils)))
    soil_spectrum = np.asarray(soil_spectrum * multiplier)
    soil_spectrum = soil_spectrum[:n_simulations]
    soil_spectrum = soil_spectrum * soil_albedo_factor.reshape(-1, 1)
    soil_spectrum = np.clip(soil_spectrum, 0, 1)
    soil_spectrum = soil_spectrum.T
    return soil_spectrum


def force_biophysical(boa_file,
                      vzn_file,
                      aot_file,
                      wvp_file,
                      qai_file,
                      output_folder,
                      n_simulations=40000,
                      n_jobs=1):
    """Creates biophysical traits from Sentinel-2 L2A FORCE

    Parameters
    ----------
    boa_file : str or Path object
        Path to the BOA l2a file generated by FORCE
    vzn_file : str or Path object
        Path to the VZN l2a file generated by FORCE
    aot_file : str or Path object
        Path to the AOT l2a file generated by FORCE
    wvp_file : str or Path object
        Path to the VWP l2a file generated by FORCE
    qai_file : str or Path object
        Path to the QAI l2a file generated by FORCE
    output_folder : str or Path object
        Path to the folder where the biophysical products will be saved
    n_simulations : int, optional
        Number of PROSPECT-D + 4AIL simulations
    n_jobs : int, optional
        Number of CPUs used during parallel processing

    Returns
    -------
    None
    """
    start_time = dt.datetime.today()
    scene_name = boa_file.stem
    params_orig = inv.build_prosail_database(n_simulations,
                                             distribution=inv.SALTELLI_DIST)

    scikit_regressor_opts = {"n_estimators": 100,
                             "min_samples_leaf": 1,
                             "n_jobs": n_jobs}

    log.info('Reading Sentinel ancillary information')
    date, level, satellite, product = scene_name.split("_")
    scene = f"{date}_{level}_{satellite}"
    output_name = f"{scene}_MASK.tif"
    mask_file = boa_file.parent / output_name
    if not mask_file.exists():
        log.info(f"Binary mask for {boa_file} not found")
        valid = cm.s2l2a_mask(qai_file)
    else:
        log.info(f"Reading binary mask from {mask_file}")
        valid = gu.get_raster_data(mask_file).astype(bool)
    
    date_obj = dt.datetime.strptime(date, "%Y%m%d")
    prj, gt, _, _, _, center, *_ = gu.raster_info(qai_file)
    dims = valid.shape
    if not np.any(valid):
        log.info(f'Print filing NANs to empty Sentinel image')
        biophysical_nan(scene, output_folder, dims, gt, prj)
        elapsed = (dt.datetime.today() - start_time).total_seconds()
        log.info(f"Finished in {elapsed/60:.1f} minutes")
        return

    # Get Day of the Year
    doy = int(date_obj.strftime("%j"))
    # Try to get overpass time from metadata
    dec_time = overpass_time_from_band_md(boa_file)
    if isinstance(dec_time, type(None)):
        stdlon = center[0]
        dec_time = LOCAL_OVERPASS_TIME
        log.info(f'Overpass time not found, assuming overpass'
                 f'at {dec_time} local time')
    else:
        stdlon = 0.
        log.info(f'Overpass time at {dec_time} GMT')

    # Get Solar angles
    sza, saa = met.calc_sun_angles(center[1],
                                   center[0], 
                                   stdlon,
                                   doy, 
                                   dec_time)

    sza, saa = map(float, [sza, saa])
    log.info(f'Getting average VZA')
    try:
        vza = gu.get_raster_data(vzn_file)
        vza = np.nanmean(vza[valid]) / VZN_SCALE

    except:
        vza = 0

    log.info(f"Getting average AOT")
    try:
        aot = gu.get_raster_data(aot_file)
        aot = np.nanmean(aot[valid]) / AOT_SCALE
    
    except:
        aot = DEFAULT_AOD

    log.info(f"Getting average WVP")
    try:
        wvp = gu.get_raster_data(wvp_file)
        wvp = np.nanmean(wvp[valid]) / WVP_SCALE

    except:
        wvp = DEFAULT_WVP

    log.info(f"Running 6S for estimation of diffuse/direct irradiance")
    skyl = get_diffuse_radiation_6S(aot, wvp, sza, saa, date_obj,
                                    altitude=0.1)

    # Stack spectral bands
    srf = []
    srf_file = SRF_LIBRARY / f'Sentinel{satellite[-2:]}.txt'
    srfs = np.genfromtxt(srf_file, dtype=None, names=True)
    for band in S2_BANDS:
        srf.append(srfs[band])

    wls_sim = np.arange(400, 2501)
    log.info(f"Builing standard soil database")
    soil_spectrum = build_soil_database(params_orig["bs"])
    log.info(f"Building {np.size(params_orig['bs'])}" 
             f"PROSPECTD+4SAIL simulations")
    if "fAPAR" in OBJ_PARAM_NAMES or "fIPAR" in OBJ_PARAM_NAMES:
        calc_fapar = True
    else:
        calc_fapar = False
    if n_jobs <= 1:
        rho_canopy_vec, params = inv.simulate_prosail_lut(params_orig,
                                                          wls_sim,
                                                          soil_spectrum,
                                                          skyl=skyl,
                                                          sza=sza,
                                                          vza=vza,
                                                          psi=0,
                                                          srf=srf,
                                                          outfile=None,
                                                          calc_FAPAR=calc_fapar,
                                                          reduce_4sail=True)

    else:
        rho_canopy_vec, params = inv.simulate_prosail_lut_parallel(
            n_jobs,
            params_orig,
            wls_sim,
            soil_spectrum,
            skyl=skyl,
            sza=sza,
            vza=vza,
            psi=0,
            srf=srf,
            outfile=None,
            calc_FAPAR=calc_fapar,
            reduce_4sail=True)

    log.info(f"Training Random forest for {','.join(OBJ_PARAM_NAMES)}")
    input_scalers = {}
    output_scalers = {}
    regs = {}
    for i, param in enumerate(OBJ_PARAM_NAMES):
        reg, input_gauss_scaler, output_gauss_scaler, _ = \
            inv.train_reg(rho_canopy_vec, params[param].reshape(-1, 1),
                          scaling_input="normalize", scaling_output="normalize",
                          regressor_opts=scikit_regressor_opts,
                          reg_method="random_forest")

        input_scalers[param] = input_gauss_scaler
        output_scalers[param] = output_gauss_scaler
        regs[param] = reg

    del rho_canopy_vec, params
    # Apply model to S2 image
    log.info(f'Applying regression model to Sentinel image')
    image_array = gu.get_raster_data(boa_file)    
    valid = np.ravel(valid)
    image_array = image_array.reshape((image_array.shape[0], -1)).T
    image_array = image_array[valid] / BOA_SCALE
    for i, param in enumerate(OBJ_PARAM_NAMES):
        output = np.full(np.size(valid), np.nan)
        log.info(f"Appliying {param} model to reflectance array")
        if np.any(valid):
            output[valid] = output_scalers[param].inverse_transform(
                    regs[param].predict(input_scalers[param].transform(
                        image_array)).reshape(-1, 1)).reshape(-1)

        output = output.reshape(dims)

        if param == 'fAPAR' or param == 'fIPAR':
            min_value = 0
            max_value = 1
        else:
            min_value = inv.prosail_bounds[param][0]
            max_value = inv.prosail_bounds[param][1]

        output = np.clip(output, min_value, max_value)
        output_name = f"{scene}_{param.upper()}.tif"
        output_file = output_folder / output_name
        log.info(f"Saving {param} in {output_file}")
        gu.save_image(output, gt, prj, output_file)
        del output

    # Narrowband to Broadban reflectance
    platform = f'Sentinel{satellite[-2:]}'
    rho_par = np.full(dims, np.nan)
    rho_nir = np.full(dims, np.nan)
    valid = valid.reshape(dims)
    rho_par[valid], rho_nir[valid] = broadband_reflectance(image_array.T,
                                                           platform)[:2]

    output_file = output_folder / f"{scene}_RHO-PAR.tif"
    gu.save_image(rho_par, gt, prj, output_file)
    del rho_par
    output_file = output_folder / f"{scene}_RHO-NIR.tif"
    gu.save_image(rho_nir, gt, prj, output_file)
    del rho_nir

    del image_array, valid, regs, output_scalers, input_scalers
    elapsed = (dt.datetime.today() - start_time).total_seconds()
    log.info(f"Finished in {elapsed/60:.1f} minutes")


def biophysical_s2_worker(scene,
                          input_folder,
                          output_folder,
                          n_simulations=50000,
                          n_jobs=1):

    boa_file = input_folder / f"{scene}_BOA.tif"
    log.info(f"Computing biophysical traits for {boa_file}")
    vzn_file = input_folder / f"{scene}_VZN.tif"
    aot_file = input_folder / f"{scene}_AOD.tif"
    wvp_file = input_folder / f"{scene}_WVP.tif"
    qai_file = input_folder / f"{scene}_QAI.tif"
    try:
        force_biophysical(boa_file,
                          vzn_file,
                          aot_file,
                          wvp_file,
                          qai_file,
                          output_folder,
                          n_simulations=n_simulations,
                          n_jobs=n_jobs)
    except Exception as e:
        log.exception(f"Biophysical data from scene {scene} not produced")


def batch_process_s2force(input_folder,
                          output_folder,
                          n_simulations=50000,
                          n_jobs=1,
                          overwrite=False,
                          start_date=None,
                          end_date=None):
    """
    Batch processes a FORCE tile datacube contatining LEVEL2 QAI products,
    such that all the pixels which should be masked have a value of zero,
    and pixels which should not be masked have a value of 1.

    Parameters
    ----------
    input_folder : str or Path object
        Path to the input FORCE tile where the masks datacube is stored.
    best_aerosol : bool
        True if want to discard interpolated aerosols.
    best_illumination : bool
        True if want to discard medium illumination conditions.
    best_wvp : bool
        True if want to discard interpolated water vapour.

    Returns
    -------
    None
    """

    input_folder = Path(input_folder)
    output_folder = Path(output_folder)
    if not output_folder.exists():
        output_folder.mkdir(parents=True)

    boa_files = sorted(list(input_folder.glob("*_BOA.tif")))
    dates = []
    for boa_file in boa_files:
        date = boa_file.stem.split("_")[0]
        skip = hp._check_bracketting_date(date,
                                          start_date=start_date,
                                          end_date=end_date)
        if skip:
            log.info(f"{boa_file} is not within the bracketting dates, "
                     f"skipping")
            continue
        
        dates.append("_".join(boa_file.stem.split("_")[:-1]))


    if n_jobs > 1:
        tp = mp.Pool(n_jobs)
        jobs = []
        for scene in dates:
            processed = check_processed_output(scene, output_folder)
            if processed and not overwrite:
                log.info(f"{scene} already processed skipping from job list")
                continue

            jobs.append((scene,
                         input_folder,
                         output_folder,
                         n_simulations,
                         1))

        tp.starmap(biophysical_s2_worker, jobs)
        tp.close()
        tp.join()

    else:
        for scene in dates:
            processed = check_processed_output(scene, output_folder)
            if processed and not overwrite:
                log.info(f"{scene} already processed skipping")
                continue

            boa_file = input_folder / f"{scene}_BOA.tif"
            log.info(f"Computing biophysical traits for {boa_file}")
            vzn_file = input_folder / f"{scene}_VZN.tif"
            aot_file = input_folder / f"{scene}_AOD.tif"
            wvp_file = input_folder / f"{scene}_WVP.tif"
            qai_file = input_folder / f"{scene}_QAI.tif"
            try:
                force_biophysical(boa_file,
                                  vzn_file,
                                  aot_file,
                                  wvp_file,
                                  qai_file,
                                  output_folder,
                                  n_simulations=n_simulations,
                                  n_jobs=mp.cpu_count() - 1)

            except Exception as e:
                log.exception(f"Biophysical data from scene {scene} not produced")


def check_processed_output(scene, output_folder):
    processed = True
    for param in OBJ_PARAM_NAMES:
        output_file = output_folder / f"{scene}_{param.upper()}.tif"
        if not output_file.exists():
            processed = False
            continue

    return processed


def biophysical_nan(scene, output_folder, dims, gt, proj):
    for param in OBJ_PARAM_NAMES:
        output_file = output_folder / f"{scene}_{param.upper()}.tif"
        output = np.full(dims, np.nan)
        gu.save_image(output, gt, proj, output_file)


def azimuth_mean(angle):
    angle = np.radians(angle)
    angle = np.arctan2(np.nanmean(np.sin(angle)),
                       np.nanmean(np.cos(angle)))
    angle = np.degrees(angle)
    return angle


def relative_azimuth(saa, vaa):
    psi = saa - vaa
    psi = np.array(psi)
    case = psi > 360
    psi[case] = psi[case] - 360
    case = psi < 0
    psi[case] = psi[case] + 360
    psi = np.abs(psi - 180)
    return psi


def find_nans(image_array):
    valid = np.ones(image_array[0].shape, dtype=bool)
    for band in image_array:
        no_data = ~np.isfinite(band)
        valid[no_data] = False

    return valid


def syn_mask(syn_flag_file, return_mask=True, overwrite=False):
    date, level, satellite, *_ = syn_flag_file.stem.split("_")
    scene = f"{date}_{level}_{satellite}"
    output_name = f"{scene}_MASK.tif"
    output_file = syn_flag_file.parent / output_name
    if output_file.exists() and not overwrite:
        if return_mask:
            log.info(f"Reading binary mask from {output_file}")
            valid = gu.get_raster_data(output_file).astype(bool)
            return valid
        else:
            log.info(f"Binary mask for {syn_flag_file} already produced")
            return None

    log.info(f"Extracting binary mask for file {syn_flag_file}")
    image_array = gu.get_raster_data(syn_flag_file)
    prj, gt, _, _, _, center, *_ = gu.raster_info(syn_flag_file)
    valid = cm.reclassify_syn_flags(image_array)
    gu.save_image(valid, gt, prj, str(output_file))
    return valid


def _biophysical_window_helper(date_obj,
                               params_orig,
                               soil_spectrum,
                               image_array,
                               vza_array,
                               vaa_array,
                               sza_array,
                               saa_array,
                               aot_array,
                               wvp_array,
                               valid,
                               srf,
                               wls_sim=np.arange(400, 2501),
                               process_window=(400, 400),
                               regressor_opts={},
                               n_jobs=1):
    if "fAPAR" in OBJ_PARAM_NAMES or "fIPAR" in OBJ_PARAM_NAMES:
        calc_fapar = True
    else:
        calc_fapar = False
    dims = valid.shape
    if not process_window:
        process_window = dims
    else:
        process_window = [process_window, process_window]
        # Check that processing window is worth appliying,
        # considering the image dimensions
        if dims[0] <= 1.5 * process_window[0]:
            process_window[0] = dims[0]
        if dims[1] <= 1.5 * process_window[1]:
            process_window[1] = dims[1]
        process_window = tuple(process_window)

    # Build the output array
    output_array = np.full((dims[0], dims[1], len(OBJ_PARAM_NAMES)), np.nan)
    row = 0
    while row < dims[0]:
        col = 0
        row_end = np.minimum(row + process_window[0], dims[0])
        while col < dims[1]:
            loop_time = dt.datetime.today()
            col_end = np.minimum(col + process_window[1], dims[1])
            log.info(f"Retrieving parameters in rows {row}:{row_end} "
                     f"and cols {col}:{col_end}")
            window_shape = (row_end - row, col_end - col)
            regs = {}
            input_scalers = {}
            output_scalers = {}
            subset = slice(row, row_end), slice(col, col_end)
            valid_subset = valid[row: row_end, col: col_end]
            if np.any(valid_subset):
                input_array = []
                for band in image_array:
                    input_array.append(band[subset].reshape(-1))

                input_array = np.transpose(np.array(input_array))
                # Convert NaNs to 0 to avoid NaN errors in RF
                # Then we will restores back the NaNs in the output
                input_array[~np.isfinite(input_array)] = 0
                vza = np.nanmean(vza_array[subset][valid_subset])
                if not np.isfinite(vza):
                    vza = 0.

                sza = np.nanmean(sza_array[subset][valid_subset])
                if not np.isfinite(sza):
                    sza = 37.5

                saa = azimuth_mean(saa_array[subset][valid_subset])
                if not np.isfinite(saa):
                    saa = 180.

                psi = relative_azimuth(saa_array[subset][valid_subset],
                                       vaa_array[subset][valid_subset])

                psi = azimuth_mean(psi)
                if not np.isfinite(psi):
                    psi = 0

                aot = np.nanmean(aot_array[subset][valid_subset])
                if not np.isfinite(aot):
                    aot = DEFAULT_AOD

                wvp = np.nanmean(wvp_array[subset][valid_subset])
                if not np.isfinite(wvp):
                    wvp = DEFAULT_WVP

                log.info(f"Running 6S for estimation of diffuse/direct "
                         f"irradiance")
                skyl = get_diffuse_radiation_6S(aot, wvp, sza, saa, date_obj,
                                                altitude=0.1)
                log.info(f"Building {np.size(params_orig['bs'])} "
                         f"PROSPECTD+4SAIL simulations")
                if n_jobs <= 1:
                    rho_canopy_vec, params = \
                        inv.simulate_prosail_lut(params_orig,
                                                 wls_sim,
                                                 soil_spectrum,
                                                 skyl=skyl,
                                                 sza=sza,
                                                 vza=vza,
                                                 psi=psi,
                                                 srf=srf,
                                                 outfile=None,
                                                 calc_FAPAR=calc_fapar,
                                                 reduce_4sail=True)

                else:
                    rho_canopy_vec, params = inv.simulate_prosail_lut_parallel(
                        mp.cpu_count() - 1,
                        params_orig,
                        wls_sim,
                        soil_spectrum,
                        skyl=skyl,
                        sza=sza,
                        vza=vza,
                        psi=psi,
                        srf=srf,
                        outfile=None,
                        calc_FAPAR=calc_fapar,
                        reduce_4sail=True)

                log.info(f"Training Random forest for "
                         f"{','.join(OBJ_PARAM_NAMES)}")
                for i, param in enumerate(OBJ_PARAM_NAMES):
                    reg, input_gauss_scaler, output_gauss_scaler, _ = \
                        inv.train_reg(rho_canopy_vec,
                                      params[param].reshape(-1, 1),
                                      scaling_input='normalize',
                                      scaling_output='normalize',
                                      regressor_opts=regressor_opts,
                                      reg_method="random_forest")

                    input_scalers[param] = input_gauss_scaler
                    output_scalers[param] = output_gauss_scaler
                    regs[param] = reg

                del rho_canopy_vec, params
                # Apply model to S3 image
                log.info(f"Applying regression model to Sentinel image")
                for i, param in enumerate(OBJ_PARAM_NAMES):
                    output = output_scalers[param].inverse_transform(
                        regs[param].predict(
                            input_scalers[param].transform(
                                input_array)).reshape(-1, 1)).reshape(-1)

                    output_array[row: row_end, col: col_end, i] = \
                        output.reshape(window_shape)

                    del output

            loop_time = dt.datetime.today() - loop_time
            log.info(f'Spatial window processed in '
                     f'{loop_time.total_seconds() / 60:.2f} minutes')

            col = int(col_end)
        row = int(row_end)

    return output_array


def syn_biophysical(boa_file,
                    vzn_file,
                    vaa_file,
                    szn_file,
                    saa_file,
                    aot_file,
                    wvp_file,
                    flag_file,
                    output_folder,
                    n_simulations=40000,
                    process_window=400,
                    n_jobs=1):
    
    start_time = dt.datetime.today()
    output_folder = Path(output_folder)
    if not output_folder.exists():
        output_folder.mkdir(parents=True)

    scene_name = boa_file.stem
    params_orig = inv.build_prosail_database(n_simulations,
                                             distribution=inv.SALTELLI_DIST)

    scikit_regressor_opts = {"n_estimators": 100,
                             "min_samples_leaf": 1,
                             "n_jobs": n_jobs}

    log.info(f'Reading Sentinel ancillary information')
    date, level, satellite, product = scene_name.split("_")
    scene = f"{date}_{level}_{satellite}"
    date_obj = dt.datetime.strptime(date, "%Y%m%dT%H%M%S")
    log.info(f"Creating valid mask")
    image_array = gu.get_raster_data(boa_file)
    prj, gt, _, _, _, center, *_ = gu.raster_info(boa_file)
    valid = syn_mask(flag_file)
    dims = valid.shape

    if not np.any(valid):
        log.info(f"Print filing NANs to empty Sentinel image")
        biophysical_nan(scene, output_folder, dims, gt, prj)
        elapsed = (dt.datetime.today() - start_time).total_seconds()
        log.info(f"Finished in {elapsed / 60:.1f} minutes")
        return

    vza_array = gu.get_raster_data(vzn_file)
    sza_array = gu.get_raster_data(szn_file)
    saa_array = gu.get_raster_data(saa_file)
    vaa_array = gu.get_raster_data(vaa_file)
    aot_array = gu.get_raster_data(aot_file)
    wvp_array = gu.get_raster_data(wvp_file)

    # Stack spectral bands
    srf = []
    srf_file = SRF_LIBRARY / f'Sentinel{satellite[-2:]}_SYN.txt'
    srfs = np.genfromtxt(srf_file, dtype=None, names=True)
    for band in S3_BANDS:
        srf.append(srfs[band])

    wls_sim = np.arange(400, 2501)
    log.info(f'Builing standard soil database')
    soil_spectrum = build_soil_database(params_orig["bs"])

    output_array = _biophysical_window_helper(date_obj,
                                              params_orig,
                                              soil_spectrum,
                                              image_array,
                                              vza_array,
                                              vaa_array,
                                              sza_array,
                                              saa_array,
                                              aot_array,
                                              wvp_array,
                                              valid,
                                              srf,
                                              wls_sim,
                                              process_window=process_window,
                                              regressor_opts=scikit_regressor_opts,
                                              n_jobs=n_jobs)

    for i, param in enumerate(OBJ_PARAM_NAMES):
        output_name = f"{scene}_{param.upper()}.tif"
        output_file = output_folder / output_name
        output = np.maximum(output_array[:, :, i], 0)
        # Restore the NaN to the output
        output[~valid] = np.nan
        gu.save_image(output, gt, prj, str(output_file))
        del output

    # Narrowband to Broadband reflectance
    platform = f'Sentinel{satellite[-2:]}_SYN'
    rho_par = np.full(dims, np.nan)
    rho_nir = np.full(dims, np.nan)
    rho_par[valid], rho_nir[valid] = broadband_reflectance(image_array[:, valid],
                                                           platform)[:2]

    output_file = output_folder / f"{scene}_RHO-PAR.tif"
    gu.save_image(rho_par, gt, prj, output_file)
    del rho_par
    output_file = output_folder / f"{scene}_RHO-NIR.tif"
    gu.save_image(rho_nir, gt, prj, output_file)
    del rho_nir, image_array

    elapsed = (dt.datetime.today() - start_time).total_seconds()
    log.info(f"Finished in {elapsed / 60:.1f} minutes")


def biophysical_syn_worker(input_folder,
                           output_folder,
                           n_simulations=50000,
                           process_window=400,
                           n_jobs=1):

    basename = get_syn_filename(input_folder)
    boa_file = input_folder / f"{basename}_REFL.vrt"
    log.info(f"Computing biophysical traits for {boa_file}")
    vzn_file = input_folder / f"{basename}_OLC_VZA.tif"
    vaa_file = input_folder / f"{basename}_OLC_VAA.tif"
    szn_file = input_folder / f"{basename}_SZA.tif"
    saa_file = input_folder / f"{basename}_SAA.tif"
    aot_file = input_folder / f"{basename}_T550.tif"
    wvp_file = input_folder / f"{basename}_water_vapour.tif"
    flag_file = input_folder / f"{basename}_SYN_flags.tif"

    try:
        syn_biophysical(boa_file,
                        vzn_file,
                        vaa_file,
                        szn_file,
                        saa_file,
                        aot_file,
                        wvp_file,
                        flag_file,
                        output_folder,
                        n_simulations=n_simulations,
                        process_window=process_window,
                        n_jobs=n_jobs)

    except Exception as e:
        log.exception(f"Biophysical data from scene {input_folder} "
                      f"not produced")


def syn_biophysical_date(boa_files,
                         vzn_files,
                         vaa_files,
                         szn_files,
                         saa_files,
                         aot_files,
                         wvp_files,
                         flag_files,
                         output_basename,
                         n_simulations=40000,
                         process_window=400,
                         n_jobs=1):

    start_time = dt.datetime.today()
    output_basename = Path(output_basename)
    output_folder = output_basename.parent
    date, level, satellite = output_basename.stem.split("_")
    scene = f"{date}_{level}_{satellite}"
    params_orig = inv.build_prosail_database(n_simulations,
                                             distribution=inv.SALTELLI_DIST)

    scikit_regressor_opts = {"n_estimators": 100,
                             "min_samples_leaf": 1,
                             "n_jobs": n_jobs}

    log.info(f'Stacking Sentinel SYN information')
    image_array = []
    vza_array = []
    sza_array = []
    saa_array = []
    vaa_array = []
    aot_array = []
    wvp_array = []
    rho_nir_array = []
    rho_par_array = []
    dates = []
    prj, gt, x_size, y_size, _, center, *_ = gu.raster_info(flag_files[0])
    dims = y_size, x_size
    for i, boa_file in enumerate(boa_files):
        _, _, satellite, *_ = boa_file.stem.split("_")
        dates.append(pd.to_datetime(dt.datetime.strptime(boa_file.parent.stem,
                                        "%Y%m%dT%H%M%S")))
        valid = syn_mask(flag_files[i])
        values = gu.get_raster_data(boa_file)
        values[:, ~valid] = np.nan
        # Narrowband 2 Broadband reflectance
        platform = f'Sentinel{satellite[-2:]}_SYN'
        rho_par = np.full(dims, np.nan)
        rho_nir = np.full(dims, np.nan)
        rho_par[valid], rho_nir[valid] = broadband_reflectance(values[:, valid],
                                                               platform)[:2]
        rho_par_array.append(rho_par)
        rho_nir_array.append(rho_nir)
        del rho_par, rho_nir
        image_array.append(values)
        values = gu.get_raster_data(vzn_files[i])
        values[~valid] = np.nan
        vza_array.append(values)
        values = gu.get_raster_data(szn_files[i])
        values[~valid] = np.nan
        sza_array.append(values)
        values = gu.get_raster_data(saa_files[i])
        values[~valid] = np.nan
        saa_array.append(values)
        values = gu.get_raster_data(vaa_files[i])
        values[~valid] = np.nan
        vaa_array.append(values)
        values = gu.get_raster_data(aot_files[i])
        values[~valid] = np.nan
        aot_array.append(values)
        values = gu.get_raster_data(wvp_files[i])
        values[~valid] = np.nan
        wvp_array.append(values)

    # Save Broadband reflectances
    rho_par_array = np.nanmean(rho_par_array, axis=0).reshape(dims)
    rho_nir_array = np.nanmean(rho_nir_array, axis=0).reshape(dims)
    output_file = output_folder / f"{scene}_RHO-PAR.tif"
    gu.save_image(rho_par_array, gt, prj, output_file)
    del rho_par_array
    output_file = output_folder / f"{scene}_RHO-NIR.tif"
    gu.save_image(rho_nir_array, gt, prj, output_file)
    del rho_nir_array

    date_obj = pd.Series(dates).mean().to_pydatetime()
    image_array = np.nanmean(np.asarray(image_array), axis=0)
    vza_array = np.nanmean(np.asarray(vza_array), axis=0)
    sza_array = np.nanmean(np.asarray(sza_array), axis=0)
    saa_array = _circular_mean(np.asarray(saa_array), axis=0)
    vaa_array = _circular_mean(np.asarray(vaa_array), axis=0)
    aot_array = np.nanmean(np.asarray(aot_array), axis=0)
    wvp_array = np.nanmean(np.asarray(wvp_array), axis=0)
    valid = np.isfinite(vza_array)
    dims = valid.shape

    if not np.any(valid):
        log.info(f"Print filing NANs to empty Sentinel image")
        biophysical_nan(scene, output_folder, dims, gt, prj)
        elapsed = (dt.datetime.today() - start_time).total_seconds()
        log.info(f"Finished in {elapsed / 60:.1f} minutes")
        return

    # Stack spectral bands
    srf = []
    srf_file = SRF_LIBRARY / f'Sentinel3A_SYN.txt'
    srfs = np.genfromtxt(srf_file, dtype=None, names=True)
    for band in S3_BANDS:
        srf.append(srfs[band])

    wls_sim = np.arange(400, 2501)
    log.info(f'Builing standard soil database')
    soil_spectrum = build_soil_database(params_orig["bs"])

    output_array = _biophysical_window_helper(date_obj,
                                              params_orig,
                                              soil_spectrum,
                                              image_array,
                                              vza_array,
                                              vaa_array,
                                              sza_array,
                                              saa_array,
                                              aot_array,
                                              wvp_array,
                                              valid,
                                              srf,
                                              wls_sim,
                                              process_window=process_window,
                                              regressor_opts=scikit_regressor_opts,
                                              n_jobs=n_jobs)

    for i, param in enumerate(OBJ_PARAM_NAMES):
        output_name = f"{scene}_{param.upper()}.tif"
        output_file = output_folder / output_name
        output = np.maximum(output_array[:, :, i], 0)
        # Restore the NaN to the output
        output[~valid] = np.nan
        gu.save_image(output, gt, prj, str(output_file))
        del output

    del output_array

    elapsed = (dt.datetime.today() - start_time).total_seconds()
    log.info(f"Finished in {elapsed / 60:.1f} minutes")


def biophysical_syn_worker_date(input_scenes,
                                output_basename,
                                n_simulations=50000,
                                process_window=400,
                                n_jobs=1):
    log.info(f"Computing biophysical traits for {output_basename}")
    boa_files = []
    vzn_files = []
    vaa_files = []
    szn_files = []
    saa_files = []
    aot_files = []
    wvp_files = []
    flag_files = []
    for input_folder in input_scenes:
        basename = get_syn_filename(input_folder)
        boa_files.append(input_folder / f"{basename}_REFL.vrt")
        vzn_files.append(input_folder / f"{basename}_OLC_VZA.tif")
        vaa_files.append(input_folder / f"{basename}_OLC_VAA.tif")
        szn_files.append(input_folder / f"{basename}_SZA.tif")
        saa_files.append(input_folder / f"{basename}_SAA.tif")
        aot_files.append(input_folder / f"{basename}_T550.tif")
        wvp_files.append(input_folder / f"{basename}_water_vapour.tif")
        flag_files.append(input_folder / f"{basename}_SYN_flags.tif")

    try:
        syn_biophysical_date(boa_files,
                             vzn_files,
                             vaa_files,
                             szn_files,
                             saa_files,
                             aot_files,
                             wvp_files,
                             flag_files,
                             output_basename,
                             n_simulations=n_simulations,
                             process_window=process_window,
                             n_jobs=n_jobs)

    except Exception as e:
        log.exception(f"Biophysical data for {output_basename} not produced")


def batch_process_s3syn_date(input_base_folder,
                             output_base_folder,
                             n_simulations=50000,
                             process_window=400,
                             n_jobs=1,
                             overwrite=False,
                             start_date=None,
                             end_date=None):
    """
    Batch processes a FORCE tile datacube contatining LEVEL2 QAI products,
    such that all the pixels which should be masked have a value of zero,
    and pixels which should not be masked have a value of 1.

    Parameters
    ----------
    input_folder : str or Path object
        Path to the input FORCE tile where the masks datacube is stored.
    best_aerosol : bool
        True if want to discard interpolated aerosols.
    best_illumination : bool
        True if want to discard medium illumination conditions.
    best_wvp : bool
        True if want to discard interpolated water vapour.

    Returns
    -------
    None
    """

    input_base_folder = Path(input_base_folder)
    output_base_folder = Path(output_base_folder)
    if not output_base_folder.exists():
        output_base_folder.mkdir(parents=True)

    scenes = sorted(list(input_base_folder.glob("*T*")))
    if isinstance(start_date, type(None)):
        start_date = dt.datetime.strptime(scenes[0].stem[:8], "%Y%m%d")
    if isinstance(end_date, type(None)):
        end_date = dt.datetime.strptime(scenes[-1].stem[:8], "%Y%m%d")

    to_process_list = []
    date_list = []
    date = start_date
    while date <= end_date:
        date_str = date.strftime('%Y%m%d')
        scenes = list(input_base_folder.glob(f"{date_str}T*"))
        if len(scenes) > 0:
            log.info(f"Found {len(scenes)} SYN scenes for date "
                     f"{date.strftime('%Y-%m-%d')}")

            basename = f"{date_str}_LEVEL2_SEN3"
            processed = check_processed_output(basename, output_base_folder)
            if not processed or overwrite:
                log.info(f"{date_str} not processed adding to job list")
                to_process_list.append(scenes)
                date_list.append(date_str)

        date = date + dt.timedelta(1)

    if n_jobs > 1:
        tp = mp.Pool(n_jobs)
        jobs = []
        for date_str, scenes in zip(date_list, to_process_list):
            output_basename = output_base_folder / f"{date_str}_LEVEL2_SEN3"
            jobs.append((scenes,
                         output_basename,
                         n_simulations,
                         process_window,
                         1,
                       ))

        tp.starmap(biophysical_syn_worker_date, jobs)
        tp.close()
        tp.join()

    else:
        for date_str, scenes in zip(date_list, to_process_list):
            output_basename = output_base_folder / f"{date_str}_LEVEL2_SEN3"
            biophysical_syn_worker_date(scenes,
                                        output_basename,
                                        n_simulations=n_simulations,
                                        process_window=process_window,
                                        n_jobs=mp.cpu_count() - 1)


def batch_process_s3syn(input_base_folder,
                        output_base_folder,
                        n_simulations=50000,
                        process_window=400,
                        n_jobs=1,
                        overwrite=False,
                        start_date=None,
                        end_date=None):
    """
    Batch processes a FORCE tile datacube contatining LEVEL2 QAI products,
    such that all the pixels which should be masked have a value of zero,
    and pixels which should not be masked have a value of 1.

    Parameters
    ----------
    input_folder : str or Path object
        Path to the input FORCE tile where the masks datacube is stored.
    best_aerosol : bool
        True if want to discard interpolated aerosols.
    best_illumination : bool
        True if want to discard medium illumination conditions.
    best_wvp : bool
        True if want to discard interpolated water vapour.

    Returns
    -------
    None
    """

    input_base_folder = Path(input_base_folder)
    scenes = sorted(list(input_base_folder.glob("*T*")))
    if n_jobs > 1:
        tp = mp.Pool(n_jobs)
        jobs = []
        for scene in scenes:
            date = scene.stem
            skip = hp._check_bracketting_date(date,
                                              start_date=start_date,
                                              end_date=end_date)
            if skip:
                log.info(f"{scene} is not within the bracketting dates, "
                         f"skipping")
                continue

            output_folder = output_base_folder / scene.stem
            basename = get_syn_filename(scene)
            processed = check_processed_output(basename, output_folder)
            if processed and not overwrite:
                log.info(f"{scene} already processed skipping from job list")
                continue

            jobs.append((scene,
                         output_folder,
                         n_simulations,
                         process_window,
                         1))

        tp.starmap(biophysical_syn_worker, jobs)
        tp.close()
        tp.join()

    else:
        for scene in scenes:
            date = scene.stem
            skip = hp._check_bracketting_date(date,
                                              start_date=start_date,
                                              end_date=end_date)
            if skip:
                log.info(f"{scene} is not within the bracketting dates, "
                         f"skipping")
                continue

            output_folder = output_base_folder / scene.stem
            basename = get_syn_filename(scene)
            processed = check_processed_output(basename, output_folder)
            if processed and not overwrite:
                log.info(f"{scene} already processed skipping")
                continue
            basename = get_syn_filename(scene)
            boa_file = scene / f"{basename}_REFL.vrt"
            log.info(f"Computing biophysical traits for {boa_file}")
            vzn_file = scene / f"{basename}_OLC_VZA.tif"
            vaa_file = scene / f"{basename}_OLC_VAA.tif"
            szn_file = scene / f"{basename}_SZA.tif"
            saa_file = scene / f"{basename}_SAA.tif"
            aot_file = scene / f"{basename}_T550.tif"
            wvp_file = scene / f"{basename}_water_vapour.tif"
            flag_file = scene / f"{basename}_SYN_flags.tif"
            try:
                syn_biophysical(boa_file,
                                vzn_file,
                                vaa_file,
                                szn_file,
                                saa_file,
                                aot_file,
                                wvp_file,
                                flag_file,
                                output_folder,
                                n_simulations=n_simulations,
                                process_window=process_window,
                                n_jobs=mp.cpu_count() - 1)
            except Exception as e:
                log.exception(f"Biophysical data from {scene} not produced")


def get_syn_filename(scene):
    basename = list(scene.glob("*_REFL.vrt"))[0]
    basename = basename.stem.replace("_REFL", "")
    return basename


def landsat_biophysical(boa_file,
                        aot_file,
                        wvp_file,
                        qai_file,
                        output_folder,
                        n_simulations=40000,
                        n_jobs=1):
    start_time = dt.datetime.today()
    scene_name = boa_file.stem
    params_orig = inv.build_prosail_database(n_simulations,
                                             distribution=inv.SALTELLI_DIST)

    scikit_regressor_opts = {"n_estimators": 100,
                             "min_samples_leaf": 1,
                             "n_jobs": n_jobs}

    log.info(f'Reading Sentinel ancillary information')
    date, level, satellite, product = scene_name.split("_")
    date_obj = dt.datetime.strptime(date, "%Y%m%d")
    scene = f"{date}_{level}_{satellite}"
    log.info(f'Creating binary QA mask')
    prj, gt, _, _, _, center, *_ = gu.raster_info(qai_file)
    output_name = f"{scene}_MASK.tif"
    mask_file = boa_file.parent / output_name
    if not mask_file.exists():
        log.info(f"Binary mask for {boa_file} not found")
        valid = gu.get_raster_data(qai_file)
        valid = cm.reclassify_qa_pixel(valid)
        gu.save_image(valid, gt, prj, mask_file)
    else:
        log.info(f"Reading binary mask from {mask_file}")
        valid = gu.get_raster_data(mask_file).astype(bool)

    dims = valid.shape
    if not np.any(valid):
        log.info(f'Print filing NANs to empty Landsat image')
        biophysical_nan(scene, output_folder, dims, gt, prj)
        elapsed = (dt.datetime.today() - start_time).total_seconds()
        log.info(f"Finished in {elapsed / 60:.1f} minutes")
        return

    # Get Day of the Year
    doy = int(date_obj.strftime("%j"))
    # Try to get overpass time from metadata
    dec_time = overpass_time_from_band_md(boa_file)
    if isinstance(dec_time, type(None)):
        stdlon = 0
        dec_time = LOCAL_OVERPASS_TIME - center[0] / 15.
        log.info(f'Overpass time not found, assuming overpass'
                 f'at {dec_time} local time')
    else:
        stdlon = 0.
        log.info(f'Overpass time at {dec_time} GMT')

    date_time = date_obj + dt.timedelta(hours=dec_time)
    # Get Solar angles
    sza, saa = met.calc_sun_angles(center[1],
                                   center[0],
                                   stdlon,
                                   doy,
                                   dec_time)

    sza, saa = map(float, [sza, saa])
    vza = 0
    log.info(f"Getting average AOT and WVP")
    try:
        data = eu.get_ECMWF_data(str(wvp_file),
                          date_time,
                          ["AOT", "TCWV"],
                          None,
                          qai_file,
                          100,
                          aod550_data_file=str(aot_file))

        aot = np.nanmean(data["AOT"][valid])
        wvp = np.nanmean(data["TCWV"][valid])
    except:
        aot = DEFAULT_AOD
        wvp = DEFAULT_WVP

    log.info(f"Running 6S for estimation of diffuse/direct irradiance")
    skyl = get_diffuse_radiation_6S(aot, wvp, sza, saa, date_obj,
                                    altitude=0.1)

    # Stack spectral bands
    srf = []
    srf_file = SRF_LIBRARY / f'Landsat{satellite[-1:]}.txt'
    srfs = np.genfromtxt(srf_file, dtype=None, names=True)
    for band in LND_BANDS:
        srf.append(srfs[band])

    wls_sim = np.arange(400, 2501)
    log.info(f"Builing standard soil database")
    soil_spectrum = build_soil_database(params_orig["bs"])
    log.info(f"Building {np.size(params_orig['bs'])} "
             f"PROSPECTD+4SAIL simulations")
    if "fAPAR" in OBJ_PARAM_NAMES or "fIPAR" in OBJ_PARAM_NAMES:
        calc_fapar = True
    else:
        calc_fapar = False
    if n_jobs <= 1:
        rho_canopy_vec, params = inv.simulate_prosail_lut(params_orig,
                                                          wls_sim,
                                                          soil_spectrum,
                                                          skyl=skyl,
                                                          sza=sza,
                                                          vza=vza,
                                                          psi=0,
                                                          srf=srf,
                                                          outfile=None,
                                                          calc_FAPAR=calc_fapar,
                                                          reduce_4sail=True)

    else:
        rho_canopy_vec, params = inv.simulate_prosail_lut_parallel(
            n_jobs,
            params_orig,
            wls_sim,
            soil_spectrum,
            skyl=skyl,
            sza=sza,
            vza=vza,
            psi=0,
            srf=srf,
            outfile=None,
            calc_FAPAR=calc_fapar,
            reduce_4sail=True)

    input_scalers = {}
    output_scalers = {}
    regs = {}
    log.info(f"Training Random forest for {','.join(OBJ_PARAM_NAMES)}")
    for i, param in enumerate(OBJ_PARAM_NAMES):
        reg, input_gauss_scaler, output_gauss_scaler, _ = \
            inv.train_reg(rho_canopy_vec, params[param].reshape(-1, 1),
                          scaling_input='normalize', scaling_output='normalize',
                          regressor_opts=scikit_regressor_opts,
                          reg_method="random_forest")

        input_scalers[param] = input_gauss_scaler
        output_scalers[param] = output_gauss_scaler
        regs[param] = reg

    del rho_canopy_vec, params
    # Apply model to Landsat image
    log.info(f'Applying regression model to Landsat image')
    image_array = gu.get_raster_data(boa_file)
    image_array = image_array[:, valid] / BOA_SCALE
    valid = np.ravel(valid)
    image_array = np.transpose(image_array)
    for i, param in enumerate(OBJ_PARAM_NAMES):

        output = np.full(np.size(valid), np.nan)
        if np.any(valid):
            output[valid] = output_scalers[param].inverse_transform(
                regs[param].predict(input_scalers[param].transform(
                    image_array)).reshape(-1, 1)).reshape(-1)

        output = output.reshape(dims)

        if param == 'fAPAR' or param == 'fIPAR':
            min_value = 0
            max_value = 1
        else:
            min_value = inv.prosail_bounds[param][0]
            max_value = inv.prosail_bounds[param][1]

        output = np.clip(output, min_value, max_value)
        output_name = f"{scene}_{param.upper()}.tif"
        output_file = output_folder / output_name
        gu.save_image(output, gt, prj, output_file)

        del output

    del regs, output_scalers, input_scalers

    # Narroband 2 Broadband reflectance
    platform = f'Landsat{satellite[-1:]}'
    rho_par = np.full(dims, np.nan)
    rho_nir = np.full(dims, np.nan)
    valid = valid.reshape(dims)
    rho_par[valid], rho_nir[valid] = broadband_reflectance(image_array.T,
                                                           platform)[:2]

    output_file = output_folder / f"{date}_{level}_{satellite}_RHO-PAR.tif"
    gu.save_image(rho_par, gt, prj, output_file)
    del rho_par, image_array, valid
    output_file = output_folder / f"{date}_{level}_{satellite}_RHO-NIR.tif"
    gu.save_image(rho_nir, gt, prj, output_file)
    del rho_nir,

    elapsed = (dt.datetime.today() - start_time).total_seconds()
    log.info(f"Finished in {elapsed / 60:.1f} minutes")


def biophysical_landsat_worker(scene,
                               input_folder,
                               ecmwf_folder,
                               output_folder,
                               n_simulations=50000,
                               n_jobs=1):

    date, level, satellite = scene.split("_")
    boa_file = input_folder / f"{scene}_BOA.tif"
    log.info(f"Computing biophysical traits for {boa_file}")
    aot_file = ecmwf_folder / f"{date}_LEVEL2_ECMWF_CAMS.nc"
    wvp_file = ecmwf_folder / f"{date}_LEVEL2_ECMWF_ERA5.nc"
    flag_file = input_folder / f"{scene}_QA_PIXEL.tif"

    try:
        landsat_biophysical(boa_file,
                            aot_file,
                            wvp_file,
                            flag_file,
                            output_folder,
                            n_simulations=n_simulations,
                            n_jobs=n_jobs)

    except Exception as e:
        log.exception(f"Biophysical data from scene {input_folder} not produced")


def batch_process_landsat(input_folder,
                          ecmwf_folder,
                          output_folder,
                          n_simulations=50000,
                          n_jobs=1,
                          overwrite=False,
                          start_date=None,
                          end_date=None):
    """
    Batch processes a FORCE tile datacube contatining LEVEL2 QAI products,
    such that all the pixels which should be masked have a value of zero,
    and pixels which should not be masked have a value of 1.

    Parameters
    ----------
    input_folder : str or Path object
        Path to the input FORCE tile where the masks datacube is stored.
    best_aerosol : bool
        True if want to discard interpolated aerosols.
    best_illumination : bool
        True if want to discard medium illumination conditions.
    best_wvp : bool
        True if want to discard interpolated water vapour.

    Returns
    -------
    None
    """

    input_folder = Path(input_folder)
    boa_files = sorted(list(input_folder.glob("*_BOA.tif")))
    dates = []
    for boa_file in boa_files:
        date = boa_file.stem.split("_")[0]
        skip = hp._check_bracketting_date(date,
                                          start_date=start_date,
                                          end_date=end_date)
        if skip:
            log.info("f{boa_file} is not within the bracketting dates, "
                     f"skipping")
            continue

        dates.append("_".join(boa_file.stem.split("_")[:-1]))


    if n_jobs > 1:
        tp = mp.Pool(n_jobs)
        jobs = []
        for scene in dates:
            processed = check_processed_output(scene, output_folder)
            if processed and not overwrite:
                log.info(f"{scene} already processed skipping from job list")
                continue

            jobs.append((scene,
                         input_folder,
                         ecmwf_folder,
                         output_folder,
                         n_simulations,
                         1))

        tp.starmap(biophysical_landsat_worker, jobs)
        tp.close()
        tp.join()

    else:
        for scene in dates:
            processed = check_processed_output(scene, output_folder)
            if processed and not overwrite:
                log.info(f"{scene} already processed skipping")
                continue

            biophysical_landsat_worker(scene,
                                       input_folder,
                                       ecmwf_folder,
                                       output_folder,
                                       n_simulations=n_simulations,
                                       n_jobs=mp.cpu_count() - 1
                                       )





def overpass_time_from_band_md(raster_file):
    fid = gdal.Open(str(raster_file), gdal.GA_ReadOnly)
    try:
        datetime_str = fid.GetRasterBand(1).GetMetadata()["Date"]
        time = pd.to_datetime(datetime_str)
        dec_time = time.hour + time.minute / 60
    except:
        dec_time = None

    return dec_time


def _circular_mean(angles, axis=None):
    angles = np.radians(angles)
    mean_angle = np.arctan2(np.nanmean(np.sin(angles), axis=axis),
                            np.nanmean(np.cos(angles), axis=axis))

    return np.degrees(mean_angle)


def broadband_reflectance(input_array, platform):
    w_file = ALBEDO_LIBRARY / f"{platform}.txt"
    weights = np.genfromtxt(w_file, delimiter=";", names=True)
    # Convert 3D to 2D
    input_array = input_array.reshape(input_array.shape[0], -1)
    # Apply the conversion
    rho_par = np.sum(input_array * weights["w_PAR"].reshape(-1, 1), axis=0)
    rho_nir = np.sum(input_array *weights["w_NIR"].reshape(-1, 1), axis=0)
    rho_sw = np.sum(input_array *weights["w_SW"].reshape(-1, 1), axis=0)
    return rho_par, rho_nir, rho_sw

