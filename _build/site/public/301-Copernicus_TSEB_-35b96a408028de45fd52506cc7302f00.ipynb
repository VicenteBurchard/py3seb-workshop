{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88af1dea-5434-483b-a5ec-cac7b4998960",
   "metadata": {},
   "source": [
    "---\n",
    "title: Running TSEB/3SEB with Satellite Imagery\n",
    "subject: Tutorial\n",
    "subtitle: Notebook to pre-process and run TSEB/3SEB using Copernicus-based satellite inputs\n",
    "short_title: Copernicus_3SEB\n",
    "authors:\n",
    "  - name: Vicente Burchard-Levine\n",
    "    affiliation:\n",
    "      - SpecLab-CSIC\n",
    "    orcid: 0000-0003-0222-8706\n",
    "    email: vburchard@ica.csic.es\n",
    "  - name: Radoslaw Guzinski\n",
    "    affiliations:\n",
    "      - DHI-GRAS\n",
    "    orcid: 0000-0003-0044-6806\n",
    "  - name: Héctor Nieto\n",
    "    affiliations:\n",
    "      - ICA-CSIC\n",
    "    orcid: 0000-0003-4250-6424\n",
    "    email: hector.nieto@ica.csic.es\n",
    "license: CC-BY-SA-4.0\n",
    "keywords: TSEB, 3SEB, Copernicus, Satellite\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8b3328-52a6-474c-aa96-01162c09919a",
   "metadata": {},
   "source": [
    "# Summary \n",
    "\n",
    "Interactive jupyter notebook showing the implementation of 3SEB with satellite imagery from the Copernicus program, namely from Sentinel-2 and Sentinel-3. \n",
    "\n",
    "This notebook will go through the pre-processing of satellite-based imagery, preparing all necesary inputs and runnign TSEB/3SEB. This includes:\n",
    "\n",
    "- Pre-processing and preparing satellite imagery\n",
    "- Sharpening Sentinel-3 LST\n",
    "- Estimating biopysical variables and ancillary parameters\n",
    "- Running TSEB and 3SEB\n",
    "\n",
    "# Instructions\n",
    "Read carefully all the text and follow the instructions.\n",
    "\n",
    ":::{hint} \n",
    "\n",
    "Once each section is read, run the jupyter code cell underneath (marked as `[]`) by clicking the icon `Run`, or pressing the keys SHIFT+ENTER of your keyboard.\n",
    "\n",
    "\n",
    ":::\n",
    "\n",
    "To start, please run the following cell to import all the packages required for this notebook. Once you run the cell below, an acknowledgement message, stating all libraries were correctly imported, should be printed on screen.\n",
    "\n",
    ":::{warning}\n",
    "\n",
    "Most of the functions implemented in this notebook are credited to the **EOMAJI-OpenEO-Toolbox** (found here: *https://github.com/DHI/EOMAJI-OpenEO-toolbox/*). \n",
    "\n",
    "This project is under active development. Features may change and bugs may exist.\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3117cb18-1ca2-4214-932c-60289f2642ef",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da99c248-424c-4df2-a364-eaf5b51d82e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import os \n",
    "import openeo\n",
    "import numpy as np\n",
    "from osgeo import gdal\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "import xarray\n",
    "from pyTSEB import TSEB\n",
    "from pyTSEB import meteo_utils as met\n",
    "from pyTSEB import net_radiation as rad\n",
    "from pyTSEB import resistances as res\n",
    "from py3seb import  py3seb \n",
    "import matplotlib.pyplot as plt\n",
    "from functions import gdal_utils as gu\n",
    "from functions.eomaji.utils import draw_utils, date_selector\n",
    "from functions.eomaji.utils.general_utils import dump_area_date_info, read_area_date_info\n",
    "from functions.eomaji.workflows import prepare_data_cubes\n",
    "from functions.eomaji.workflows.decision_tree_sharpener import run_decision_tree_sharpener\n",
    "from functions.eomaji.workflows.sentinel2_preprocessing import split_datasets_to_tiffs\n",
    "from functions.eomaji.workflows.meteo_preprocessing import get_meteo_data\n",
    "from functions.eomaji.utils.raster_utils import resample_to_s2\n",
    "\n",
    "print('libraries imported correctly!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35955a9-a907-4000-9f16-0186a428c703",
   "metadata": {},
   "source": [
    "# General workflow\n",
    "\n",
    "The general workflow to run TSEB/3SEB using Sentinel imagery from the Copernicus program is depicted below. \n",
    "\n",
    "The main processing steps are:\n",
    "1. Acquring and pre-processing Sentinel-2 and Sentinel-3 imagery from the [**CDSE**](https://dataspace.copernicus.eu/)\n",
    "2. Performing TIR sharpening on Sentinel-3 LST (1km ->20m) using [**pyDMS**](https://github.com/radosuav/pyDMS)\n",
    "3. Estimating biophysical variables (e.g. LAI) from RTM inversion using [**pypro4sail**](https://github.com/hectornieto/pypro4sail)\n",
    "4. Retrieving ancillary vegetation parameters per plant functional type based on global land cover map.\n",
    "5. Acquiring and pre-processing ERA-5 reanalysis meteo data using [**meteo_utils**](https://github.com/hectornieto/meteo_utils)\n",
    "6. Running TSEB and 3SEB using [**pyTSEB**](https://github.com/hectornieto/pyTSEB) and [**py3SEB**](https://github.com/VicenteBurchard/py3SEB), respectively \n",
    "\n",
    ":::{figure} ./input/figures/S2_processing_flowchart.png\n",
    ":alt: S2\n",
    ":name: S2-flowchart\n",
    "TSEB input processing using Copernicus datasets (figure credit: Héctor Nieto)\n",
    ":::\n",
    "\n",
    ":::{note}\n",
    "While the figure above depicts the use of Landsat imagery to further correct the sharpened LST product, we won´t be implementing this in this notebook as we will solely focus on the use of Copernicus products from the CDSE. \n",
    "\n",
    "The use of Landsat to better capture the high resolution LST variability during the sharpening process is based on the results from [**Guzinski et al. 2023**](https://doi.org/10.1016/j.jag.2023.103587).\n",
    ":::\n",
    "\n",
    ":::{note}\n",
    "Futhermore, the global Land Cover map used in this notebook is ESA's 10m [**WorldCover2021**](https://worldcover2021.esa.int/) instead of the 100m [**Global Dynamic Land Cover**](https://land.copernicus.eu/en/products/global-dynamic-land-cover) map fom Copernicus Land Monitoring Service. \n",
    ":::\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a2d2ff-8957-4fb9-a7c2-eac3f09709e6",
   "metadata": {},
   "source": [
    "# Requirements\n",
    "\n",
    ":::{important}\n",
    "\n",
    "In order to execute this notebook, you will need to register in the [**Copernicus Data Space Ecosystem (CSDE)**](https://dataspace.copernicus.eu/) to process Sentinel-2 and Sentinel-3 imagery.\n",
    "\n",
    "Along with this, to acquire ERA-5 weather data you should first register to the Copernicus' [**Climate Data Store**](https://cds.climate.copernicus.eu/user/register)\n",
    "and [Atmospheric Data Store](https://ads.atmosphere.copernicus.eu/user/register) systems.\n",
    "\n",
    "Once registered, follow the steps in the [**CDS User Guide**](https://cds.climate.copernicus.eu/how-to-api) where you will get a personal URL and KEY for both CDS and ADS.\n",
    "\n",
    "You will then need to create a ```.adsapirc``` and a ```.cdsapirc``` file with the API key like this:\n",
    "\n",
    "``` bash\n",
    ".adsapirc\n",
    "url: https://ads.atmosphere.copernicus.eu/api\n",
    "key: <api_key>\n",
    "```\n",
    "and\n",
    "```` bash\n",
    ".cdsapirc\n",
    "url: https://cds.climate.copernicus.eu/api\n",
    "key: <api_key>\n",
    "````\n",
    "\n",
    "Examples files are provided in./.adsapirc_example and ./cdsapirc_example.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbaef06-5fa2-4bac-aaf1-9aa320ba1a6b",
   "metadata": {},
   "source": [
    "# Data preparation \n",
    "\n",
    "This notebook will make use of Sentinel data freely available from the [**Copernicus Data Space Ecosystem (CDSE)**](https://dataspace.copernicus.eu/) platform. \n",
    "\n",
    "The first step is to generate data cubes of the datasets needed over you area of interest. \n",
    "\n",
    ":::{important}\n",
    "To access the data and execute the notebook, you will need to register a free account here: *https://dataspace.copernicus.eu/*\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01a5d49-17cb-4411-a3bc-17b0e9b60aeb",
   "metadata": {},
   "source": [
    "## Select area of interest \n",
    "\n",
    "You have the option of drawing a polygon on the map, for the area you want to process or you can specifying the bounding box (bbox) with the format **[minx, miny, maxx, maxy]** i.e. **[min_lon, min_lat, max_lon, max_lat]**\n",
    "\n",
    ":::{note}\n",
    "\n",
    "We have pre-selected a bounding box around the WES experimental Almond Orchard with bbox = [-121.35,37.45, -121.10, 37.65]. Change this or use the map tool to draw a polygon to process a different area. However, the notebook is designed to be used over the WES Almond Orchard.\n",
    ":::\n",
    "\n",
    ":::{warning}\n",
    "\n",
    "We suggest to start with small region of interest to limit processing time. For large areas the download and aggregation of data in OpenEO may take some time and fail.\n",
    "\n",
    ":::\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebe0225-e36d-48ba-81ae-2177c39e17ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "map, bboxs = draw_utils.draw_aoi()\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105b4747-14d0-4b8f-b01d-a779c9b3f8a6",
   "metadata": {},
   "source": [
    "## Select a date from the available Sentinel-3 imagery\n",
    "\n",
    "Here, we will select satellite imagery over the same data and area as the UAV overpass from the WES almond orchard as from the previous notebook (./403-UAV-3SEB.ipynb).\n",
    "\n",
    "As mentioned before, the bbox is set over the WES almond orchard area of interest but if you want to use the area that you drew on the map, you can uncomment \n",
    "``` bash\n",
    "#bbox = bboxs[-1]  # Uncomment this if you want to use the polygon drawn above\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f307fb-c0eb-42d3-bb39-b53f8dcd87cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define search parameters\n",
    "start_date = \"2024-04-16\"\n",
    "end_date = \"2024-04-16\"\n",
    "bbox = [-121.35,37.45, -121.10, 37.65] # please insert a bbox here in the form of [minx, miny, maxx, maxy]\n",
    "#bbox = bboxs[-1] # Uncomment this if you want to use the polygon drawn above\n",
    "\n",
    "max_cloud_cover = 10  # Filter out high-cloud-coverage scenes\n",
    "\n",
    "# Search for available Sentinel-3 imagery\n",
    "date_selection = date_selector.get_available_dates(\n",
    "    start_date=start_date,\n",
    "    end_date=end_date,\n",
    "    bbox=bbox,\n",
    "    max_cloud_cover=max_cloud_cover\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f70d02-abd5-47e8-9e40-f62183c2d04f",
   "metadata": {},
   "source": [
    "## Connect to OpenEO Backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662bccf4-d30f-448b-92d6-6c7f06c93a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = openeo.connect(\"https://openeo.dataspace.copernicus.eu\")\n",
    "connection.authenticate_oidc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bc6c33-3e17-4777-b608-7a261577b616",
   "metadata": {},
   "source": [
    "## Pre-process Sentinel 2 and Sentinel 3 data for the specified AOI and date\n",
    "\n",
    "We will create a folder to save the processed imagery in **./dataset/sentinel_imagery**\n",
    "\n",
    "\n",
    "Specify the path to store the processed satellite imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1093e1a7-7b83-4036-9472-1ef7c7d106f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify directory to save satellite imagery\n",
    "data_dir = \"./dataset/sentinel_imagery\"\n",
    "if not os.path.isdir(data_dir):\n",
    "    os.mkdir(data_dir)\n",
    "\n",
    "date = date_selection.value\n",
    "#date, bbox = read_area_date_info(\n",
    "#    dir=data_dir\n",
    "#) # <-- USE THIS IF YOU WANT TO REUSE BBOX AND DATE FROM FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5986807-3e06-4aed-bc74-7531a0b7bcac",
   "metadata": {},
   "source": [
    "Now we will begin the pre-proceessing of sentinel-2 and sentinel-3 imagery and generate data cubes\n",
    "\n",
    ":::{warning}\n",
    "\n",
    "As mentioned previously, this section might take some time, especially for larger areas. For the pre-selected AOI over the WES almond orchard, it could take **over 15-20 minutes**. \n",
    "\n",
    "You can go to **https://openeo.dataspace.copernicus.eu/** and sign in to your account and follow the status of your jobs and see any errors.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1774dd-edad-4718-b14a-8f1def82292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_path, s3_path, vza_path, worldcover_path, dem_s2_path, dem_s3_path, sentinel3_acq_time, = prepare_data_cubes.prepare_data_cubes(\n",
    "    connection=connection,\n",
    "    bbox=bbox,\n",
    "    date=date,\n",
    "    sentinel2_search_range = 3,\n",
    "    out_dir = data_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effecd32-620d-4ae4-8005-5c28c8705fa2",
   "metadata": {},
   "source": [
    "### Store AOI and data for subsequent use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cfb03b-e0cc-4fa3-abcb-fc89917bbe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_area_date_info(\n",
    "    date = date, \n",
    "    bbox = bbox, \n",
    "    out_dir = data_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1c2c22-6d64-45b4-9d2c-71da97b00b0f",
   "metadata": {},
   "source": [
    "## Visualize sentinel-2 and Sentinel-3 data cubes\n",
    "\n",
    "Here, we can inspect the sentinel imagery.\n",
    "\n",
    "Sentinel-2 band information:\n",
    "\n",
    ":::{figure} ./input/figures/S2_bands_info.jpg\n",
    ":alt: S2\n",
    ":name: S2-bands\n",
    "Sentinel-2 MSI bands information (figure taken from [Pasqualotto et al. 2019](https://ieeexplore.ieee.org/document/8909218))\n",
    ":::\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c579ffb-c6a3-479d-add0-33af90cc4a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open sentinel-2 data\n",
    "s2_cube =  xarray.open_dataset(s2_path)\n",
    "band_names = [\"B02\", \"B03\", \"B04\", \"B05\", \"B07\", \"B08\", \"B8A\", \"B11\", \"B12\"]  # These are the Sentinel 2 bands to use for the sharpening\n",
    "s2_array = s2_cube[band_names].to_array(dim=\"band\").rio.write_crs(rasterio.crs.CRS.from_string(s2_cube.crs.spatial_ref).to_string())\n",
    "\n",
    "# open sentinel-3 data\n",
    "s3_cube = xarray.open_dataset(s3_path)\n",
    "lst_array = s3_cube.LST.rio.write_crs(rasterio.crs.CRS.from_string(s3_cube.crs.spatial_ref).to_string())\n",
    "\n",
    "# get extent [minx, maxx, miny, maxy]\n",
    "te = [float(s2_cube['x'].min()), float(s2_cube['x'].max()), float(s2_cube['y'].min()), float(s2_cube['y'].max())]\n",
    "\n",
    "# Read specific bands (5=NIR, 2=Red,1=green and 0=blue)\n",
    "nir_band = s2_array[5,:,:]\n",
    "red_band = s2_array[2,:,:]\n",
    "green_band = s2_array[1,:,:]\n",
    "blue_band = s2_array[0,:,:]\n",
    "\n",
    "# calc NDVI\n",
    "ndvi_ar = (nir_band - red_band)/(nir_band + red_band)\n",
    "\n",
    "# normalize to visualize RGB\n",
    "red_norm = (red_band - np.nanmin(red_band)) / (np.nanmax(red_band) - np.nanmin(red_band))  # scale 0–1\n",
    "green_norm = (green_band - np.nanmin(green_band)) / (np.nanmax(green_band) - np.nanmin(green_band))  # scale 0–1\n",
    "blue_norm = (blue_band - np.nanmin(green_band)) / (np.nanmax(blue_band) - np.nanmin(blue_band))  # scale 0–1\n",
    "\n",
    "rgb_stack =  np.dstack((red_norm, green_norm, blue_norm))\n",
    "\n",
    "# plot imagery\n",
    "fig, axes = plt.subplots(2,3, figsize = (12,8), constrained_layout=True)\n",
    "ax = axes[0,0]\n",
    "ax.imshow(rgb_stack*5.5, extent = te)\n",
    "ax.set_title('S2-True Color', fontsize=12)\n",
    "\n",
    "ax = axes[0,1]\n",
    "im1 = ax.imshow(ndvi_ar, extent = te, cmap='YlGn', vmin=0.3, vmax=0.7)\n",
    "ax.set_title('S2-NDVI', fontsize=12)\n",
    "cb = plt.colorbar(im1, ax=ax, shrink=0.65)\n",
    "cb.set_label(' (-)', fontsize=14)\n",
    "\n",
    "ax = axes[0,2]\n",
    "im2 = ax.imshow(lst_array.values[0,:,:], extent = te, cmap='coolwarm', vmin=290, vmax=310)\n",
    "ax.set_title('S3-LST', fontsize=12)\n",
    "cb = plt.colorbar(im2, ax=ax, shrink=0.65)\n",
    "cb.set_label('(K)', fontsize=14)\n",
    "\n",
    "# zoom to WES almonds\n",
    "ax = axes[1,0]\n",
    "ax.imshow(rgb_stack*5.5, extent = te)\n",
    "ax.set_title('Zoom to Almond orchard', fontsize=12)\n",
    "ax.set_xlim(654900, 655850)\n",
    "ax.set_ylim(4156600, 4157500)\n",
    "\n",
    "# zoom to WES almonds\n",
    "ax = axes[1,1]\n",
    "im1 = ax.imshow(ndvi_ar, extent = te, cmap='YlGn', vmin=0.3, vmax=0.7)\n",
    "ax.set_title('Zoom to Almond orchard', fontsize=12)\n",
    "ax.set_xlim(654900, 655850)\n",
    "ax.set_ylim(4156600, 4157500)\n",
    "\n",
    "# zoom to WES almonds\n",
    "ax = axes[1,2]\n",
    "im2 = ax.imshow(lst_array.values[0,:,:], extent = te, cmap='coolwarm', vmin=290, vmax=310)\n",
    "ax.set_title('Zoom to Almond orchard', fontsize=12)\n",
    "ax.set_xlim(654900, 655850)\n",
    "ax.set_ylim(4156600, 4157500)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1d758c-b561-4ed4-872c-6269fa2381c7",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "As you can see, we do not have any plot-level information with the LST data from Sentinel-3 because it is too coarse.\n",
    "\n",
    "For this reason, it is important to perform an LST sharpening to obtain high resolution LST at the sub-plot level\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d706b9a-4d71-43d9-8b2d-62b1963f3c7b",
   "metadata": {},
   "source": [
    "# Sentinel-3 LST Sharpening\n",
    "\n",
    "Sentinel-3 SLSTR sensor provides thermal infrared (TIR) images at 1km spatial resolution but we can use the information from Sentinel-2 images (with 20m pixel size) to sharpnen the TIR images to 20m to obtain information at the subplot scale, especially important for agricultural applications. \n",
    "\n",
    "In this case, we will use the Data Mining Sharpener (DMS) which was first proposed by Gao et al. (2012) (for more information see paper [**here**](https://doi.org/10.3390/rs4113287)) which assumes a relationship between optical shortwave bands and LST. We will use the pyDMS code (available here: https://github.com/radosuav/pyDMS) to perform this sharpening.\n",
    "\n",
    "## Open S2 and S3 data cubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc6c032-766a-4d61-b5da-0c6d39326941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open sentinel-2 data\n",
    "s2_cube =  xarray.open_dataset(s2_path)\n",
    "band_names = [\"B02\", \"B03\", \"B04\", \"B05\", \"B07\", \"B08\", \"B8A\", \"B11\", \"B12\"]  # These are the Sentinel 2 bands to use for the sharpening\n",
    "s2_array = s2_cube[band_names].to_array(dim=\"band\").rio.write_crs(rasterio.crs.CRS.from_string(s2_cube.crs.spatial_ref).to_string())\n",
    "\n",
    "# open sentinel-3 data\n",
    "s3_cube = xarray.open_dataset(s3_path)\n",
    "lst_array = s3_cube.LST.rio.write_crs(rasterio.crs.CRS.from_string(s3_cube.crs.spatial_ref).to_string())\n",
    "mask_array = ((s3_cube.confidence_in < 16384).astype(float).rio.write_crs(rasterio.crs.CRS.from_string(s3_cube.crs.spatial_ref).to_string()))\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f710c3a9-2ae0-43aa-b85a-4e0e6ea98bbe",
   "metadata": {},
   "source": [
    "## Run the Data Mining Sharpener\n",
    "Here we run the data mining sharpening algorithm which is based on [**pyDMS**](https://github.com/radosuav/pyDMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a6079a-e9ad-4145-9f4b-9ce8fe42c1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sharpened_data = run_decision_tree_sharpener(\n",
    "    high_res_dataarray=s2_array,\n",
    "    low_res_dataarray=lst_array,\n",
    "    low_res_mask=mask_array,\n",
    "    mask_values=[1],\n",
    "    cv_homogeneity_threshold=0,\n",
    "    moving_window_size=30,\n",
    "    disaggregating_temperature=True,\n",
    "    n_jobs=3,\n",
    "    n_estimators=30,\n",
    "    max_samples=0.8,\n",
    "    max_features=0.8,\n",
    ")\n",
    "\n",
    "# specify output path for sharpened LST\n",
    "lst_outdir = Path(s3_path).parent/\"sharpened_LST.tif\"\n",
    "\n",
    "print(f'Saving sharpened LST to {lst_outdir}')\n",
    "sharpened_data.band_data.rio.to_raster(lst_outdir)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86703533-7c6e-47d6-853b-50c616f65fca",
   "metadata": {},
   "source": [
    "### Visualize LST sharpening\n",
    "Here we plot the sharpened images but you can also inspect the images using QGIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6322505-98ef-42fd-84e2-f131e7f866b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot imagery\n",
    "fig, axes = plt.subplots(2,3, figsize = (12,8), constrained_layout=True)\n",
    "\n",
    "ax = axes[0,0]\n",
    "ax.imshow(rgb_stack*5.5, extent = te)\n",
    "ax.set_title('S2-True Color', fontsize=12)\n",
    "\n",
    "ax = axes[0,1]\n",
    "im2 = ax.imshow(lst_array.values[0,:,:], extent = te, cmap='coolwarm', vmin=290, vmax=310)\n",
    "ax.set_title('S3-LST (1km)', fontsize=12)\n",
    "#cb = plt.colorbar(im2, ax=ax, shrink=0.65)\n",
    "#cb.set_label('(K)', fontsize=14)\n",
    "\n",
    "ax = axes[0,2]\n",
    "im1 = ax.imshow(sharpened_data['band_data'].values[0,:,:], extent = te, cmap='coolwarm',vmin=290, vmax=310)\n",
    "ax.set_title('S3-LST-Sharpened (20m)', fontsize=12)\n",
    "cb = plt.colorbar(im1, ax=ax, shrink=0.7)\n",
    "cb.set_label(' (K)', fontsize=12)\n",
    "\n",
    "# zoom to WES almonds\n",
    "ax = axes[1,0]\n",
    "ax.imshow(rgb_stack*5.5, extent = te)\n",
    "ax.set_title('Zoom to Almond orchard', fontsize=12)\n",
    "ax.set_xlim(654900, 655850)\n",
    "ax.set_ylim(4156600, 4157500)\n",
    "\n",
    "# zoom to WES almonds\n",
    "ax = axes[1,1]\n",
    "im2 = ax.imshow(lst_array.values[0,:,:], extent = te, cmap='coolwarm', vmin=290, vmax=310)\n",
    "ax.set_title('Zoom to Almond orchard', fontsize=12)\n",
    "ax.set_xlim(654900, 655850)\n",
    "ax.set_ylim(4156600, 4157500)\n",
    "\n",
    "# zoom to WES almonds\n",
    "ax = axes[1,2]\n",
    "im2 = ax.imshow(sharpened_data['band_data'].values[0,:,:], extent = te, cmap='coolwarm', vmin=290, vmax=310)\n",
    "ax.set_title('Zoom to Almond orchard', fontsize=12)\n",
    "ax.set_xlim(654900, 655850)\n",
    "ax.set_ylim(4156600, 4157500)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdd03eb-5e73-47c6-8da6-26e667b9ad3c",
   "metadata": {},
   "source": [
    "# Meteo and biophysical processing\n",
    "\n",
    "Now we need to process the other TSEB/3SEB inputs including the biophysical variables and meterological forcings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f20e5e-dc20-46ce-b804-5ad83df86675",
   "metadata": {},
   "source": [
    "Re-Check if all necessary imagery were pre-processed correctly \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8c91b7-69af-4039-ba83-eafc706dfe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_path, s3_path, vza_path, worldcover_path, dem_s2_path, dem_s3_path, sentinel3_acq_time = prepare_data_cubes.prepare_data_cubes(\n",
    "    connection=connection,\n",
    "    bbox=bbox,\n",
    "    date=date,\n",
    "    sentinel2_search_range = 3,\n",
    "    out_dir = data_dir,\n",
    ")\n",
    "\n",
    "# correct sentinel-3 acquisition time to UTC (seems that the function does not produce correct UTC time)\n",
    "date_ts = pd.to_datetime(s3_cube.t.values[0])\n",
    "sentinel3_acq_time = float(date_ts.hour)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7c6a7d-c2da-4aa0-8e64-7b096fca4c84",
   "metadata": {},
   "source": [
    "## Estimation of biophysical variables\n",
    "\n",
    "The **prepare_data_cubes** function from the [EOMAJI-OpenEO-Toolbox](https://github.com/DHI/EOMAJI-OpenEO-toolbox/blob/main/eomaji/workflows/prepare_data_cubes.py#L58)  internally estimates the necessary biophysical variables (i.e. LAI, Fg (green fraction), Fc (veg. fractional cover)) using the [**BIOPAR**](https://marketplace-portal.dataspace.copernicus.eu/catalogue/app-details/21#iss=https%3A%2F%2Fidentity.dataspace.copernicus.eu%2Fauth%2Frealms%2FCDSE) tool from the CDSE. \n",
    "\n",
    "This method essentially implements a hybrid radiative transfer modeling (RTM) method where a machine learning (ML) algorithm (e.g. Artificial Neural Network-ANN) to estimate biophysical variables is trained using synthetic top-of-canopy reflectances from the RTM (i.e. PROSAIL) and then applied to the Sentinel-2 bands to retrieve the different variables.\n",
    "\n",
    ":::{figure} ./input/figures/Biophysical_processor_figure.png\n",
    ":alt: S2-BIOPAR\n",
    ":name: S2-BIOPAR\n",
    "Flow chart showing how the BIOPAR products are generated operationally (figure taken from [S2 Toolbox ATDB](https://step.esa.int/docs/extra/ATBD_S2ToolBox_V2.1.pdf))\n",
    ":::\n",
    "\n",
    "\n",
    "You can find the documentation of the biophysical processor [**here**](https://step.esa.int/docs/extra/ATBD_S2ToolBox_V2.1.pdf) and an adapted and more efficient version of this method can be found in the [**pypro4sail**](https://github.com/hectornieto/pypro4sail) python package. \n",
    "\n",
    ":::{note}\n",
    "\n",
    "The notebook **./502-Biophysical_Traits_RTM.ipynb** goes into more details on how to implement these types of methods for estimating biophysical traits, offerring a step-by-step guide.\n",
    "\n",
    ":::\n",
    "\n",
    "Other vegetation parameters, such as canopy height (Hc), which are not estimated through the RTM inversion, need to be estimated using other methods. In this case, these are estimated using a look-up-table over a global land cover map, assigning vegetation parameters based on different plant functional types. In this case of Hc, values are then scaled based on LAI for crops or herbaceous vegetation which have strong phenological dynamics. \n",
    "\n",
    "In other applications, ancillary non-copernicus datasets can be ingested, such as [**GEDI's**](https://gedi.umd.edu/data/products/) canopy height product, which can serve to characterize Hc in forested ecosystems.\n",
    "\n",
    "You can find more information in Guzinski et al. ([2020](https://doi.org/10.3390/rs12091433), [2021](https://doi.org/10.1109/JSTARS.2021.3122573), [2023](https://doi.org/10.1016/j.jag.2023.103587)).\n",
    "\n",
    "In the [**EOMAJI-OpenEO-Toolbox**](https://github.com/DHI/EOMAJI-OpenEO-toolbox/). , this procedure is done internally using the **split_datasets_to_tiffs** function after the sentinel-3 pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b884f62-d5fa-4641-aff7-b7cd2ca18b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tif_path = split_datasets_to_tiffs(s2_path = s2_path, s3_path = s3_path, worldcover_path = worldcover_path, date = date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08f3457-fd2f-48a7-8764-31d439a3b719",
   "metadata": {},
   "source": [
    "### Visualize biophysical inputs \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2db88fa-6222-477d-8fee-08c0607c4983",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = {'LAI':{'cmap':'YlGn', 'range':[0,5]},\n",
    "             'FCOVER':{'cmap':'Greens', 'range':[0,1]},\n",
    "             'H_C':{'cmap':'cividis', 'range':[0,10]}\n",
    "            }\n",
    "\n",
    "cmaps = ['PiYG', 'Greens', 'cividis']\n",
    "\n",
    "# make a 2x3 \n",
    "fig, axes = plt.subplots(2,3, figsize = (12,8), constrained_layout=True)\n",
    "i = 0\n",
    "for var in variables.keys():\n",
    "    filename = tif_path/f'{str(date)[:4]}{str(date)[5:7]}{str(date)[-2:]}_{var}.tif'\n",
    "    fid = gdal.Open(str(filename))\n",
    "    ar = fid.GetRasterBand(1).ReadAsArray()\n",
    "    \n",
    "    ax = axes[0,i]\n",
    "    ax.imshow(ar, extent = te, cmap=variables[var]['cmap'], vmin=variables[var]['range'][0], vmax=variables[var]['range'][1])\n",
    "    ax.set_title(f'{var}', fontsize=12)\n",
    "\n",
    "    # zoom to WES almonds\n",
    "    ax = axes[1,i]\n",
    "    ax.imshow(ar, extent = te, cmap=variables[var]['cmap'], vmin=variables[var]['range'][0], vmax=variables[var]['range'][1])\n",
    "    ax.set_title('Zoom to Almond orchard', fontsize=12)\n",
    "    ax.set_xlim(654900, 655850)\n",
    "    ax.set_ylim(4156600, 4157500)\n",
    "    i = i + 1\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f004fa-d390-4f70-a748-e7a653564ea5",
   "metadata": {},
   "source": [
    ":::{tip} Question\n",
    "In the WES almond orchard, do the biophysical values seem reasonable? What about the spatial pattern of Hc? Have a look at the land use map (*./dataset/sentinel_imagery/20240416_ad419755/WordlCover2021.tif*) and see how the orchard is classified? (see WorldView documentation [**here**](https://worldcover2021.esa.int/data/docs/WorldCover_PUM_V2.0.pdf))\n",
    "\n",
    "It is often challenging to apply global methods over tree orchards which have complex characteristics and tend to be misclassified or simply classified as CROP even though they have quite different structural characteristics, especially those with co-ocurring cover crops.\n",
    "::: \n",
    "\n",
    ":::{tip} Question\n",
    "How do you think this will affect the TSEB modeling and flux outputs?\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e786ad-c088-42de-a509-50c2ff02df15",
   "metadata": {},
   "source": [
    "## Get ERA-5 Meteo data \n",
    "\n",
    "Fetch data from Atmosphere Data Store and Climate Data Store and calculate meteorological forcings.\n",
    "\n",
    "The notebook depends on [**Climate Data Store**](https://cds.climate.copernicus.eu/) and the [**Atmosphere Data Store**](https://cds.climate.copernicus.eu/). To access data from these two sources, you need to create a profile in the [**Climate Data Store**](https://cds.climate.copernicus.eu/) and obtain an API key as described in the documentation:\n",
    "* [**CDS User Guide**](https://cds.climate.copernicus.eu/how-to-api)\n",
    "\n",
    "\n",
    ":::{important}\n",
    "\n",
    "To run the next functions, you need to create a ```.adsapirc``` and a ```.cdsapirc``` file with the API key like this:\n",
    "\n",
    "``` bash\n",
    ".adsapirc\n",
    "url: https://ads.atmosphere.copernicus.eu/api\n",
    "key: <api_key>\n",
    "```\n",
    "and\n",
    "```` bash\n",
    ".cdsapirc\n",
    "url: https://cds.climate.copernicus.eu/api\n",
    "key: <api_key>\n",
    "````\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630b22f9-3a7f-407d-8ea9-96eb05cfeb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify path to .cdsapirc and .adsapirc files with your URL and KEY\n",
    "cds_file = \"./.cdsapirc\"\n",
    "ads_file = \"./.adsapirc\"\n",
    "\n",
    "meteo_output_path = get_meteo_data(\n",
    "    date = str(date),\n",
    "    bbox = bbox,\n",
    "    dem_path = dem_s3_path,\n",
    "    acq_time = sentinel3_acq_time,\n",
    "    data_dir=dem_s3_path.parent,\n",
    "    cds_credentials_file=cds_file,\n",
    "    ads_credentials_file=ads_file,\n",
    ")\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb278f7-6fa0-4d0a-b7c0-11cc1fdaf2a1",
   "metadata": {},
   "source": [
    "# Running TSEB\n",
    "\n",
    "Now, we have all necessary inputs to run TSEB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1cc39d-111f-4c56-8318-0f647cfa9dd5",
   "metadata": {},
   "source": [
    "### Open satellite imagery as arrays\n",
    "\n",
    "Here, we will create input dictionary (i.e. input_dict) which will store all the inputs necessary to run TSEB and 3SEB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f4ee4f-c53d-4b50-9af2-9bdb8a34fbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictioanry to store inputs arrays\n",
    "input_dict = {}\n",
    "\n",
    "# input directory\n",
    "input_dir = tif_path\n",
    "\n",
    "# meteo dir\n",
    "meteo_dir = input_dir / 'meteo_data'\n",
    "\n",
    "# store inputs as in input dict\n",
    "input_vars = ['LST', 'LAI', 'F_G', 'FCOVER', 'H_C', 'W_C', 'VZA', 'SZA', 'RHO_NIR_C', 'RHO_VIS_C', 'TAU_NIR_C', 'TAU_VIS_C']\n",
    "\n",
    "for var in input_vars:\n",
    "    if var == 'LST':\n",
    "        filename = input_dir / 'sharpened_LST.tif'\n",
    "    else:\n",
    "        filename = input_dir/f'{str(date)[:4]}{str(date)[5:7]}{str(date)[-2:]}_{var}.tif'\n",
    "\n",
    "    # get raster info \n",
    "    if var == 'LAI':\n",
    "        proj, gt, x_size, y_size, extent, center_geo, _ = gu.raster_info(str(filename))\n",
    "\n",
    "    fid = gdal.Open(str(filename))\n",
    "    ar = fid.GetRasterBand(1).ReadAsArray()\n",
    "    # store within input dictionary\n",
    "    input_dict[var] = ar \n",
    "    \n",
    "\n",
    "meteo_var = [\"EA\", \"p\", \"u\", \"S_dn_24\", \"S_dn\", \"T_A1\", 'LW-IN', 'ETR']\n",
    "# use LAI as a template\n",
    "template_file = Path(tif_path)/f\"{str(date).replace('-', '')}_LAI.tif\"\n",
    "\n",
    "for var in meteo_var:\n",
    "    filename = list(meteo_dir.glob(f'*{var}.tif'))[0]\n",
    "    # resample to sentinel-2 resolution\n",
    "    fid = gu.resample_with_gdalwarp(filename, template_file, \"bilinear\")\n",
    "    #fid = gdal.Open(str(filename))\n",
    "    ar = fid.GetRasterBand(1).ReadAsArray()\n",
    "    input_dict[var] = ar \n",
    "\n",
    "# parameterize constant variables\n",
    "constant_params = {'RHO_NIR_S':0.07, # reflectance of soil in NIR\n",
    "                  'RHO_VIS_S':0.28, # reflectance of soil in VIS\n",
    "                  'E_S':0.95, # soil emissivity\n",
    "                  'E_V':0.99, # vegetation emissivity\n",
    "                  'Z0_SOIL':0.01, # soil roughness\n",
    "                  'KN_C':0.0038, # Kondo & Ishida (1997) coefficient for rough surfaces\n",
    "                  'KN_B':0.0120, # Kustas and Norman (1999) after Sauer and Norman (1995)\n",
    "                  'ALPHA_PT':1.26, # alpha parameter in Priestley-Taylor Initialization\n",
    "                  'X_LAD':1., # Chi parameter for leaf angle distribution\n",
    "                  'Fc':1, # fractional cover of vegetation\n",
    "                  'Fg':1, # fraction of vegetation that is photosynthetically active\n",
    "                  'LEAF_WIDTH':0.05 # effective leaf width\n",
    "                      \n",
    "                  }\n",
    "\n",
    "for key in constant_params.keys():\n",
    "    ar = np.full_like(input_dict['LAI'], constant_params[key])\n",
    "    input_dict[key] = ar \n",
    "\n",
    "\n",
    "print(f'Inputs stored in input_dict: \\n{list(input_dict.keys())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ecbf9d-9cde-446b-a743-de8c283627d5",
   "metadata": {},
   "source": [
    "### Net Radiation and clumping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24b0564-a4ec-4d06-8792-b310840f8f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate diffuse/direct ratio\n",
    "difvis, difnir, fvis, fnir = TSEB.rad.calc_difuse_ratio(input_dict['S_dn'], input_dict['SZA'], press=input_dict['p'])\n",
    "skyl = fvis * difvis + fnir * difnir\n",
    "Sdn_dir = (1. - skyl) * input_dict['S_dn']\n",
    "Sdn_dif = skyl * input_dict['S_dn']\n",
    "\n",
    "# incoming long wave radiation\n",
    "emisAtm = rad.calc_emiss_atm(input_dict['EA'], input_dict['T_A1'])\n",
    "Lsky = emisAtm * met.calc_stephan_boltzmann(input_dict['T_A1'])\n",
    "\n",
    "# We need to compute SAA\n",
    "doy = date_ts.dayofyear\n",
    "dec_time = date_ts.hour + date_ts.minute / 60.\n",
    "sza, saa = met.calc_sun_angles(center_geo[1], center_geo[0], 0,doy, dec_time)\n",
    "\n",
    "\n",
    "# to take into account row strucure on vegetation clumping\n",
    "row_direction = 90\n",
    "psi = row_direction - saa\n",
    "\n",
    "\n",
    "Omega0 = TSEB.CI.calc_omega0_Kustas(input_dict['LAI'], input_dict['FCOVER'], x_LAD=input_dict['X_LAD'], isLAIeff=True)\n",
    "Omega = TSEB.CI.calc_omega_rows(input_dict['LAI'], input_dict['FCOVER'], theta=input_dict['SZA'],\n",
    "                                psi=psi, w_c=input_dict['W_C'],\n",
    "                                x_lad=input_dict['X_LAD'])\n",
    "\n",
    "F = input_dict['LAI']/input_dict['FCOVER']\n",
    "# effective LAI (tree crop)\n",
    "input_dict['LAI_EFF'] =  F * Omega\n",
    "\n",
    "\n",
    "\n",
    "sn_veg, sn_soil = TSEB.rad.calc_Sn_Campbell(input_dict['LAI'], input_dict['SZA'], Sdn_dir, Sdn_dif, fvis, fnir,\n",
    "                                                    input_dict['RHO_VIS_C'],\n",
    "                                                    input_dict['TAU_VIS_C'],\n",
    "                                                    input_dict['RHO_NIR_C'],\n",
    "                                                    input_dict['TAU_NIR_C'],\n",
    "                                                    input_dict['RHO_VIS_S'],\n",
    "                                                    input_dict['RHO_NIR_S'],\n",
    "                                                    x_LAD=input_dict['X_LAD'], LAI_eff=input_dict['LAI_EFF']) \n",
    "\n",
    "sn_veg[~np.isfinite(sn_veg)] = 0\n",
    "sn_soil[~np.isfinite(sn_soil)] = 0\n",
    "\n",
    "input_dict['SN_VEG'] = sn_veg\n",
    "input_dict['SN_SOIL'] = sn_soil\n",
    "\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e367bb-dda3-434f-869a-e9e28497d51e",
   "metadata": {},
   "source": [
    "### Landscape roughness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb93cb8-9c5a-45ba-a018-b2eb8afb7b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_0m, d_0 = TSEB.res.calc_roughness(input_dict['LAI'],\n",
    "                                    input_dict['H_C'],\n",
    "                                    input_dict['W_C'],\n",
    "                                    np.full_like(input_dict['LAI'], TSEB.res.CROP))\n",
    "d_0[d_0 < 0] = 0\n",
    "z_0m[z_0m < input_dict['Z0_SOIL']] = constant_params['Z0_SOIL']\n",
    "\n",
    "# store in input dictionary\n",
    "input_dict['d_0'] = d_0\n",
    "input_dict['Z_0M'] = z_0m\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d801f6f-e2b3-4031-a43d-42be8d8c2870",
   "metadata": {},
   "source": [
    "# Running TSEB\n",
    "\n",
    "Now we have processed all necessary inputs to run TSEB! Let's run TSEB and store the results in an output dictionary (i.e. model_outdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7687f498-e75b-45f8-8389-8b137148f156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output dictionary to save model results\n",
    "model_outdict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4d242a-ce76-468b-a3e8-5640ec3058b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Norman and Kustas 1995 resistance framework\n",
    "Resistance_flag=[0,{}]\n",
    "# using constant ratio appraoch to estimate G\n",
    "G_constant = 0.35\n",
    "calcG = [[1], G_constant]\n",
    "\n",
    "[flag_PT_all, T_soil, T_veg, T_AC, Ln_soil, Ln_veg, LE_veg, H_veg,\n",
    "     LE_soil, H_soil, G_mod, R_S, R_X, R_A, u_friction, L, n_iterations] = TSEB.TSEB_PT(input_dict['LST'],\n",
    "                                                                                        input_dict['VZA'],\n",
    "                                                                                        input_dict['T_A1'],\n",
    "                                                                                        input_dict['u'],\n",
    "                                                                                        input_dict['EA'],\n",
    "                                                                                        input_dict['p'],\n",
    "                                                                                        input_dict['SN_VEG'],\n",
    "                                                                                        input_dict['SN_SOIL'],\n",
    "                                                                                        input_dict['LW-IN'],\n",
    "                                                                                        input_dict['LAI'],\n",
    "                                                                                        input_dict['H_C'],\n",
    "                                                                                        input_dict['E_V'],\n",
    "                                                                                        input_dict['E_S'],\n",
    "                                                                                        input_dict['Z_0M'],\n",
    "                                                                                        input_dict['d_0'],\n",
    "                                                                                        100,\n",
    "                                                                                        100,\n",
    "                                                                                        leaf_width=input_dict['LEAF_WIDTH'],\n",
    "                                                                                        alpha_PT=input_dict['ALPHA_PT'],\n",
    "                                                                                        f_c=input_dict['FCOVER'],\n",
    "                                                                                        f_g=input_dict['F_G'],\n",
    "                                                                                        calcG_params=calcG,\n",
    "                                                                                        resistance_form=Resistance_flag)\n",
    "\n",
    "# save ouputs in outdict \n",
    "LE = LE_veg + LE_soil\n",
    "H = H_veg + H_soil\n",
    "Rn = (Ln_veg + sn_veg) + (Ln_soil + sn_soil)\n",
    "\n",
    "# Estimate daily ET assuming LE/Sdn ratio remains relatively constant troughout the day\n",
    "le_ratio = LE/input_dict['S_dn']\n",
    "ET_daily = met.flux_2_evaporation(input_dict['S_dn_24'] * le_ratio, input_dict['T_A1'], time_domain=24)\n",
    "\n",
    "# evaporative stress index\n",
    "esi = ET_daily/input_dict['ETR']\n",
    "\n",
    "# save outputs to dictionary\n",
    "model_outdict['LE_TSEB-PT'] = LE\n",
    "model_outdict['LEc_TSEB-PT'] = LE_veg\n",
    "model_outdict['H_TSEB-PT'] = H\n",
    "model_outdict['Rn_TSEB-PT'] = Rn\n",
    "model_outdict['G_TSEB-PT'] = G_mod\n",
    "model_outdict['ET_TSEB-PT'] = ET_daily\n",
    "model_outdict['ESI_TSEB-PT'] = esi\n",
    "model_outdict['Flags_TSEB-PT'] = flag_PT_all\n",
    "\n",
    "te = [float(s2_cube['x'].min()), float(s2_cube['x'].max()), float(s2_cube['y'].min()), float(s2_cube['y'].max())]\n",
    "\n",
    "variables = ['LE', 'H', 'Rn', 'G']\n",
    "# visualizing outputs \n",
    "#fig, axes = plt.subplots(2,2, figsize=(10,8))\n",
    "i = 0\n",
    "fig, axes = plt.subplots(4,2, figsize=(10,16))\n",
    "\n",
    "for var in variables:\n",
    "    # entire ROI\n",
    "    ax = axes[i,0]\n",
    "    if var == 'LE':\n",
    "        im = ax.imshow(model_outdict[f'{var}_TSEB-PT'], vmin=0, vmax=600, cmap='PuBu', extent = te)\n",
    "    elif var == 'H':\n",
    "        im = ax.imshow(model_outdict[f'{var}_TSEB-PT'], vmin=0, vmax=600, cmap='OrRd',  extent = te)\n",
    "    elif var == 'Rn':\n",
    "        im = ax.imshow(model_outdict[f'{var}_TSEB-PT'], vmin=0, vmax=800, cmap='plasma',  extent = te)\n",
    "    else:\n",
    "        im = ax.imshow(model_outdict[f'{var}_TSEB-PT'], vmin=0, vmax=200, cmap='copper',  extent = te)\n",
    "\n",
    "    ax.set_title(f'{var}', fontsize=14)\n",
    "    flux_mean = int(np.round(np.nanmean(model_outdict[f'{var}_TSEB-PT']),0))\n",
    "    ax.text(0.01,0.1, f'mean:\\n{flux_mean} W/$m^2$', transform=ax.transAxes)\n",
    "    \n",
    "    # zoom to Almonds\n",
    "    ax = axes[i,1]\n",
    "    if var == 'LE':\n",
    "        im = ax.imshow(model_outdict[f'{var}_TSEB-PT'], vmin=0, vmax=600, cmap='PuBu', extent = te)\n",
    "    elif var == 'H':\n",
    "        im = ax.imshow(model_outdict[f'{var}_TSEB-PT'], vmin=0, vmax=600, cmap='OrRd',  extent = te)\n",
    "    elif var == 'Rn':\n",
    "        im = ax.imshow(model_outdict[f'{var}_TSEB-PT'], vmin=0, vmax=800, cmap='plasma',  extent = te)\n",
    "    else:\n",
    "        im = ax.imshow(model_outdict[f'{var}_TSEB-PT'], vmin=0, vmax=200, cmap='copper',  extent = te)\n",
    "\n",
    "    # Add colorbar \n",
    "    cbar = fig.colorbar(im, ax=ax)\n",
    "    cbar.set_label(f'{var} (W/$m^2$)')  # Add title to colorbar\n",
    "    ax.set_xlim(654900, 655850)\n",
    "    ax.set_ylim(4156600, 4157500)\n",
    "    ax.set_title(f'Zoom to Almond Orchard', fontsize=12)\n",
    "\n",
    "\n",
    "    i = i + 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30985465-f0be-4912-90e7-e3161e1e876e",
   "metadata": {},
   "source": [
    ":::{tip} Question\n",
    "What do you think is driving the spatial patterns of modelled LE/H from TSEB? Have a look at the biophysical variables and parameters above.  \n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459ca797-a6fe-46aa-b7f0-f1492514dbce",
   "metadata": {},
   "source": [
    "# Running 3SEB\n",
    "\n",
    "As discussed previously, 3SEB uses esentially the same inputs as TSEB but needs to parameterize both vegetation layers i.e. tree crop and cover crop.\n",
    "\n",
    ":::{important}\n",
    "In general, 3SEB should only be applied in agro-forestry systems with two distinct co-occurring vegetation layers such as savannas or tree crops with cover crops. Normally, at the satellite scale, we usually only apply 3SEB over pixels that are classified as savannas and using a global tree cover fraction product such as [**this**](https://land.copernicus.eu/en/products/high-resolution-layer-forests-and-tree-cover?tab=tree_cover_density). \n",
    "\n",
    "However, it is still a challenge to find global land cover maps that seperate tree crops with and without cover crops as the agronomic practices may change year to year. \n",
    "\n",
    "In other land types, such as grasslands, herbaceous crops, or tree crops without cover crops, it is recommend to implement TSEB.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023c3f2b-f3e3-4cc2-a2ae-a1393da8edf9",
   "metadata": {},
   "source": [
    "### Characterizing 3SEB specific variables\n",
    "\n",
    "Here we will characterterize the two vegetation layers by making certain assumptions while attempting to best characterize the target Almond orchards. \n",
    "\n",
    "Separating the contribution of tree and grass layers within a mixed is often challenging at global scales. In orchards with cover crops, we could use information of the different phenology of tree and cover crops to seperate both signals as done in the application of 3SEB using proximal sensing (see ./303-py3SEB-Proximal). However, ideally this seperation could be done more dynamically without prescribe information, through, for example, spectral unmixing algorithms, but this is still in development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9984817b-854c-4897-9018-cb3e7eaf9f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumed cover crop fraction cover is 1 (this refers to fraction of vegetation cover in the substate(soil+cover crop)\n",
    "input_dict['Fc_C'] = np.full_like(input_dict['LAI'], 0.2)\n",
    "input_dict['Fc_CC'] = np.full_like(input_dict['LAI'], 1)\n",
    "\n",
    "# assumed tree crop has a fixed local LAI\n",
    "## tree crop \n",
    "F = 2.5\n",
    "# tree crop LAI\n",
    "input_dict['LAI_C']=  input_dict['Fc_C'] * F\n",
    "\n",
    "## cover crop\n",
    "input_dict['LAI_CC'] =  input_dict['LAI'] - input_dict['LAI_C']\n",
    "input_dict['LAI_CC'][input_dict['LAI_CC']<0] = 0\n",
    "\n",
    "# cover crop height (assiming the Almond orchard target)\n",
    "input_dict['H_C_TREE'] = np.full_like(input_dict['LAI'], 3.)\n",
    "input_dict['H_CC'] = np.full_like(input_dict['LAI'], 0.4)\n",
    "\n",
    "# green fraction\n",
    "input_dict['Fg_C'] = np.full_like(input_dict['LAI'], 0.9)\n",
    "input_dict['Fg_CC'] = np.full_like(input_dict['LAI'], 1)\n",
    "\n",
    "# Leaf width\n",
    "input_dict['LEAF_WIDTH_C'] = np.full_like(input_dict['LAI'], 0.05)\n",
    "input_dict['LEAF_WIDTH_CC'] = np.full_like(input_dict['LAI'], 0.01)\n",
    "\n",
    "\n",
    "# calculate clumping index\n",
    "## tree crop\n",
    "Omega0 = TSEB.CI.calc_omega0_Kustas(input_dict['LAI_C'], input_dict['Fc_C'], x_LAD=input_dict['X_LAD'], isLAIeff=True)\n",
    "Omega = TSEB.CI.calc_omega_rows(input_dict['LAI_C'], input_dict['Fc_C'], theta=input_dict['SZA'],\n",
    "                                psi=psi, w_c=input_dict['W_C'], x_lad=input_dict['X_LAD'])\n",
    "# effective LAI (tree crop)\n",
    "input_dict['LAI_EFF_C'] =  F * Omega\n",
    "\n",
    "## understory vegetation\n",
    "Omega0_un = TSEB.CI.calc_omega0_Kustas(input_dict['LAI_CC'], input_dict['Fc_CC'], x_LAD=input_dict['X_LAD'], isLAIeff=True)\n",
    "Omega_un = TSEB.CI.calc_omega_Kustas(Omega0_un, input_dict['W_C'], w_C=input_dict['SZA'])\n",
    "\n",
    "F_cc = input_dict['LAI_CC']/input_dict['Fc_CC']\n",
    "# effective LAI (cover crop)\n",
    "input_dict['LAI_EFF_CC'] =  F_cc * Omega_un\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025f1498-8b2e-469c-85c6-36404f3f9ba5",
   "metadata": {},
   "source": [
    "### 3-Source Net Radiation Modeling\n",
    "Estimate shortwave radiation transmission using an adapted Campbell 1998 model (adapted for 3 layers). See the Supplementary Information of [Burchard-Levine et al. (2022)](https://doi.org/10.1111/gcb.16002) for more details. \n",
    "- sn_ov = net shortwave radiation for overstory (tree crop)\n",
    "- sn_un = net shortwave radiation for understory (cover crop)\n",
    "- sn_soil =  net shortwave radiation for soil "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bda474-c43b-4f7f-8d24-74efb2199357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate radiation transmission using Campbell 1998 model (adapted for 3 layers)\n",
    "sn_ov, sn_s, sn_un = py3seb.calc_Sn_Campbell(input_dict['LAI_C'],\n",
    "                                       input_dict['LAI_CC'],\n",
    "                                       input_dict['SZA'],\n",
    "                                       Sdn_dir,\n",
    "                                       Sdn_dif,\n",
    "                                       fvis,\n",
    "                                       fnir,\n",
    "                                       input_dict['RHO_VIS_C'],\n",
    "                                       input_dict['RHO_VIS_C'],\n",
    "                                       input_dict['TAU_VIS_C'],\n",
    "                                       input_dict['TAU_VIS_C'],\n",
    "                                       input_dict['RHO_NIR_C'],\n",
    "                                       input_dict['RHO_NIR_C'],\n",
    "                                       input_dict['TAU_NIR_C'],\n",
    "                                       input_dict['TAU_NIR_C'],\n",
    "                                       input_dict['RHO_VIS_S'],\n",
    "                                       input_dict['RHO_NIR_S'],\n",
    "                                       input_dict['H_C_TREE'],\n",
    "                                       0.25 * input_dict['H_C_TREE'],\n",
    "                                       input_dict['W_C'],\n",
    "                                       input_dict['Fc_C'],\n",
    "                                       LAI_eff=input_dict['LAI_EFF_C'],\n",
    "                                       LAI_eff_sub=input_dict['LAI_EFF_CC'])\n",
    "\n",
    "sn_ov[~np.isfinite(sn_ov)] = 0\n",
    "sn_s[~np.isfinite(sn_s)] = 0\n",
    "sn_un[~np.isfinite(sn_un)] = 0\n",
    "\n",
    "input_dict['SN_C'] = sn_ov\n",
    "input_dict['SN_CC'] = sn_un\n",
    "input_dict['SN_S'] = sn_s\n",
    "\n",
    "\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393a2bfc-d925-4870-b7ce-bd636edd7413",
   "metadata": {},
   "source": [
    "### Landscape roughness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54e7459-221a-42a0-858e-9b8f7382ad22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate tree crop roughness parameters taking into account LAIeff using Raupach 1994 model\n",
    "z_0M_factor, d_0_factor = py3seb.raupach_94(input_dict['LAI_EFF_C'])\n",
    "d_0 = input_dict['H_C_TREE']*d_0_factor\n",
    "z_0M = input_dict['H_C_TREE']*z_0M_factor\n",
    "\n",
    "d_0[d_0 < 0] = 0\n",
    "z_0M[z_0M < input_dict['Z0_SOIL']] = constant_params['Z0_SOIL']\n",
    "\n",
    "# understory/secondary vegetation (i.e. Cover crop)\n",
    "z_0m_un, d_0_un = TSEB.res.calc_roughness(input_dict['LAI_EFF_CC'],\n",
    "                                          input_dict['H_CC'],\n",
    "                                          input_dict['W_C'],\n",
    "                                          np.full_like(input_dict['LAI'], TSEB.res.GRASS))\n",
    "d_0_un[d_0_un < 0] = 0\n",
    "z_0m_un[z_0m_un < input_dict['Z0_SOIL']] = constant_params['Z0_SOIL']\n",
    "\n",
    "input_dict['d_0_C'] = d_0\n",
    "input_dict['Z_0M_C'] = z_0M\n",
    "\n",
    "input_dict['d_0_CC'] = d_0_un\n",
    "input_dict['Z_0M_CC'] = z_0m_un\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1945482-12ac-4406-b535-f4aa489e3a8f",
   "metadata": {},
   "source": [
    "## Running 3SEB-PT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb0e27f-fab5-41f5-a00c-beb7e2db77f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "[flag_PT_all, T_S, T_C, T_C_sub, T_AC, L_n_sub, L_nC, Ln_C_sub, Ln_S, LE_C, H_C, LE_C_sub, H_C_sub,\n",
    " LE_S, H_S, G_mod, R_S, R_sub, R_X, R_A, u_friction, L, n_iterations] = py3seb.ThreeSEB_PT(input_dict['LST'],\n",
    "                                                                                         input_dict['VZA'],\n",
    "                                                                                         input_dict['T_A1'],\n",
    "                                                                                         input_dict['u'],\n",
    "                                                                                         input_dict['EA'],\n",
    "                                                                                         input_dict['p'],\n",
    "                                                                                         input_dict['SN_C'],\n",
    "                                                                                         input_dict['SN_S'],\n",
    "                                                                                         input_dict['SN_CC'],\n",
    "                                                                                         input_dict['LW-IN'],\n",
    "                                                                                         input_dict['LAI_C'],\n",
    "                                                                                         input_dict['LAI_CC'],\n",
    "                                                                                         input_dict['H_C_TREE'],\n",
    "                                                                                         input_dict['H_CC'],\n",
    "                                                                                         input_dict['E_V'],\n",
    "                                                                                         input_dict['E_V'],#change e_v cover crop\n",
    "                                                                                         input_dict['E_S'],\n",
    "                                                                                         input_dict['Z_0M_C'],\n",
    "                                                                                         input_dict['Z_0M_CC'],\n",
    "                                                                                         input_dict['d_0_C'],\n",
    "                                                                                         input_dict['d_0_CC'],\n",
    "                                                                                         100,\n",
    "                                                                                         100,\n",
    "                                                                                         leaf_width=input_dict['LEAF_WIDTH_C'],\n",
    "                                                                                         leaf_width_sub=input_dict['LEAF_WIDTH_CC'],\n",
    "                                                                                         f_c=input_dict['Fc_C'],\n",
    "                                                                                         f_c_sub=input_dict['Fc_CC'],\n",
    "                                                                                         f_g=input_dict['Fg_C'],\n",
    "                                                                                         f_g_sub=input_dict['Fg_CC'],\n",
    "                                                                                         calcG_params=calcG,\n",
    "                                                                                         resistance_form=Resistance_flag)\n",
    "# save ouputs in outdict \n",
    "LE = LE_C + LE_C_sub + LE_S\n",
    "H = H_C + H_S + H_C_sub\n",
    "\n",
    "Rn_C = L_nC + sn_ov\n",
    "Rn_C_sub = Ln_C_sub + sn_un\n",
    "Rn_S = Ln_S + sn_s\n",
    "Rn = Rn_C + Rn_C_sub + Rn_S\n",
    "\n",
    "# Estimate daily ET assuming LE/Sdn ratio remains relatively constant troughout the day\n",
    "le_ratio = LE/input_dict['S_dn']\n",
    "ET_daily = met.flux_2_evaporation(input_dict['S_dn_24'] * le_ratio, input_dict['T_A1'], time_domain=24)\n",
    "\n",
    "# evaporative stress index\n",
    "esi = ET_daily/input_dict['ETR']\n",
    "\n",
    "# save outputs to dictionary\n",
    "model_outdict['LE_3SEB-PT'] = LE\n",
    "model_outdict['LEc_3SEB-PT'] = LE_C\n",
    "model_outdict['LEcc_3SEB-PT'] = LE_C_sub\n",
    "model_outdict['H_3SEB-PT'] = H\n",
    "model_outdict['Rn_3SEB-PT'] = Rn\n",
    "model_outdict['G_3SEB-PT'] = G_mod\n",
    "model_outdict['ET_3SEB-PT'] = ET_daily\n",
    "model_outdict['ESI_3SEB-PT'] = esi\n",
    "\n",
    "model_outdict['Flags_3SEB-PT'] = flag_PT_all\n",
    "\n",
    "# visualizing outputs \n",
    "variables = ['LE', 'H', 'Rn', 'G']\n",
    "i = 0\n",
    "fig, axes = plt.subplots(4,2, figsize=(10,16))\n",
    "\n",
    "for var in variables:\n",
    "    # entire ROI\n",
    "    ax = axes[i,0]\n",
    "    if var == 'LE':\n",
    "        im = ax.imshow(model_outdict[f'{var}_3SEB-PT'], vmin=0, vmax=600, cmap='PuBu', extent = te)\n",
    "    elif var == 'H':\n",
    "        im = ax.imshow(model_outdict[f'{var}_3SEB-PT'], vmin=0, vmax=600, cmap='OrRd',  extent = te)\n",
    "    elif var == 'Rn':\n",
    "        im = ax.imshow(model_outdict[f'{var}_3SEB-PT'], vmin=0, vmax=800, cmap='plasma',  extent = te)\n",
    "    else:\n",
    "        im = ax.imshow(model_outdict[f'{var}_3SEB-PT'], vmin=0, vmax=200, cmap='copper',  extent = te)\n",
    "\n",
    "    ax.set_title(f'{var}', fontsize=14)\n",
    "    flux_mean = int(np.round(np.nanmean(model_outdict[f'{var}_3SEB-PT']),0))\n",
    "    ax.text(0.01,0.1, f'mean:\\n{flux_mean} W/$m^2$', transform=ax.transAxes)\n",
    "    \n",
    "    # zoom to Almonds\n",
    "    ax = axes[i,1]\n",
    "    if var == 'LE':\n",
    "        im = ax.imshow(model_outdict[f'{var}_3SEB-PT'], vmin=0, vmax=600, cmap='PuBu', extent = te)\n",
    "    elif var == 'H':\n",
    "        im = ax.imshow(model_outdict[f'{var}_3SEB-PT'], vmin=0, vmax=600, cmap='OrRd',  extent = te)\n",
    "    elif var == 'Rn':\n",
    "        im = ax.imshow(model_outdict[f'{var}_3SEB-PT'], vmin=0, vmax=800, cmap='plasma',  extent = te)\n",
    "    else:\n",
    "        im = ax.imshow(model_outdict[f'{var}_3SEB-PT'], vmin=0, vmax=200, cmap='copper',  extent = te)\n",
    "\n",
    "    # Add colorbar \n",
    "    cbar = fig.colorbar(im, ax=ax)\n",
    "    cbar.set_label(f'{var} (W/$m^2$)')  # Add title to colorbar\n",
    "    ax.set_xlim(654900, 655850)\n",
    "    ax.set_ylim(4156600, 4157500)\n",
    "    ax.set_title(f'Zoom to Almond Orchard', fontsize=12)\n",
    "\n",
    "\n",
    "    i = i + 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5515900d-cc5d-4d3c-9b0b-d36ab3244d16",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "\n",
    "In this case, the comparison between TSEB-PT and 3SEB-PT is not entirely fair since we used tailored inputs specific for the Almond orchards in 3SEB-PT for the entire scene while TSEB-PT used a dynamic vegetation parameterization based on global methods. \n",
    "\n",
    "You can re-run TSEB-PT using parameter values expected for the Almond Orchard and see if the results change significantly over the experimental area.\n",
    ":::\n",
    "\n",
    ":::{tip} Next steps and Questions\n",
    "* You can evaluate both TSEB-PT and 3SEB-PT over the tower footprint. **Hint:** see *./403-UAV_3SEB.ipynb*\n",
    "* How to these satellite-based outputs compare to the UAV results from *./403-UAV_3SEB.ipynb*?\n",
    "* Any other global datasets that can be used to improve this workflow for tree crops?\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aac2baf-b523-4731-af53-a74d22a7c122",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "* The Copernicus program offers a large set of products that are suitable to model ET globally\n",
    "* 3SEB presents the advantage of partitioning fluxes from two distict coexisting canopies, suitable to better simluate orchards with cover crops\n",
    "* However, it remains a challenge to well characterize and parameterize the two vegetation canopies solely relying on global datasets\n",
    "* [...]\n",
    "\n",
    ":::{note}\n",
    "Please feel free comment any thoughts. This is work in progress!!!\n",
    ":::"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
